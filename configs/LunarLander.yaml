timesteps_per_batch: 4800                 # Number of timesteps to run per rollout
max_timesteps_per_episode: 1200           # Max number of timesteps per episode
n_updates_per_iteration: 5                # Number of times to update policy per iteration
lr: 0.005                                  # Learning rate of policy optimizer
gamma: 0.99                             # Discount factor for the rewards 
lam: 0.95                                 # Lambda Parameter for GAE 
clip: 0.2                                 # Clip ratio for ppo loss. Using recomended 0.2
clip_grad: True
max_grad_norm: 0.5                       # Gradient clipping threshold
lr_gamma: 0.995                          # Gamma for scheduler
n_sgd_batches: 1                         # Number of batches for sgd

# Misc parameters
save_freq: 50                             # How often to save in number of iterations
seed: ~ 