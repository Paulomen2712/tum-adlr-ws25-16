{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO\n",
    "---\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "from model.ppo_parallel import PPO\n",
    "from model.network import ActorCritic\n",
    "from model.environments import LunarContinuous\n",
    "from logger import WandbSummaryWritter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the hyperparameters in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {\n",
    "#     'timesteps_per_batch': 1024 ,                # Number of timesteps to run per batch\n",
    "#     'max_timesteps_per_episode': 1200,           # Max number of timesteps per episode\n",
    "#     'n_updates_per_iteration': 5,                # Number of times to update actor/critic per iteration\n",
    "#     'lr': 2.5e-4 ,                                # Learning rate of actor optimizer\n",
    "#     'gamma': 0.95,                               # Discount factor to be applied when calculating Rewards-To-Go\n",
    "#     'clip': 0.2                                 # Recommended 0.2, helps define the threshold to clip the ratio during SGA\n",
    "# }\n",
    "hyperparameters = {'gamma': 0.999, 'lr_gamma': 0.995,\n",
    "                   'max_timesteps_per_episode': 1600,\n",
    "\t\t\t\t\t\t\t'clip_range': 0.2, 'lr': 0.005 }\n",
    "\n",
    "misc_hyperparameters = {\n",
    "    'num_workers': 8  ,\n",
    "    'seed': None \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise wandb session in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpmsaraiva2712\u001b[0m (\u001b[33mpmsaraiva2712-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\wandb\\run-20241201_210723-0phaveix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/0phaveix' target=\"_blank\">cerulean-oath-245</a></strong> to <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/0phaveix' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/0phaveix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = WandbSummaryWritter(project='lunar', config =hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model fo the desired timestamps. Alternatively can specify a checkpoint to continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'ppo_parallel_checkpoints/charmed-armadillo-108/ppo_policy_960.pth'\n",
    "LOAD_MODEL = False\n",
    "\n",
    "ppo = PPO(logger, **hyperparameters, **misc_hyperparameters)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    \n",
    "    env = LunarContinuous().make_environment()\n",
    "    model = ActorCritic(env.observation_space.shape[0], env.action_space.shape[0])\n",
    "    model.load_state_dict(torch.load(checkpoint))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Model\n",
    "\n",
    "Train model for specified amount of timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Length: 122.1\n",
      "Average Episodic Return: -256.5\n",
      "Average Loss: 0.00234\n",
      "Timesteps So Far: 4884\n",
      "Iteration took: 11.75 secs\n",
      "Current learning rate: 0.004876243765609375\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Length: 126.37\n",
      "Average Episodic Return: -236.2\n",
      "Average Loss: -0.00024\n",
      "Timesteps So Far: 9686\n",
      "Iteration took: 11.23 secs\n",
      "Current learning rate: 0.004755550652328859\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #3 --------------------\n",
      "Average Episodic Length: 124.36\n",
      "Average Episodic Return: -133.21\n",
      "Average Loss: -0.00098\n",
      "Timesteps So Far: 14536\n",
      "Iteration took: 9.26 secs\n",
      "Current learning rate: 0.004637844844091639\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #4 --------------------\n",
      "Average Episodic Length: 131.24\n",
      "Average Episodic Return: -137.84\n",
      "Average Loss: -0.00139\n",
      "Timesteps So Far: 19392\n",
      "Iteration took: 9.18 secs\n",
      "Current learning rate: 0.004523052401373088\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #5 --------------------\n",
      "Average Episodic Length: 132.35\n",
      "Average Episodic Return: -119.11\n",
      "Average Loss: -0.00168\n",
      "Timesteps So Far: 24289\n",
      "Iteration took: 9.05 secs\n",
      "Current learning rate: 0.004411101214744006\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #6 --------------------\n",
      "Average Episodic Length: 121.62\n",
      "Average Episodic Return: -160.08\n",
      "Average Loss: -0.00164\n",
      "Timesteps So Far: 29154\n",
      "Iteration took: 10.82 secs\n",
      "Current learning rate: 0.0043019209595734804\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #7 --------------------\n",
      "Average Episodic Length: 138.63\n",
      "Average Episodic Return: -126.85\n",
      "Average Loss: -0.0015\n",
      "Timesteps So Far: 34006\n",
      "Iteration took: 14.26 secs\n",
      "Current learning rate: 0.004195443051852896\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #8 --------------------\n",
      "Average Episodic Length: 145.61\n",
      "Average Episodic Return: -80.37\n",
      "Average Loss: -0.00169\n",
      "Timesteps So Far: 38811\n",
      "Iteration took: 15.88 secs\n",
      "Current learning rate: 0.004091600605113372\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #9 --------------------\n",
      "Average Episodic Length: 136.81\n",
      "Average Episodic Return: -66.81\n",
      "Average Loss: -0.00176\n",
      "Timesteps So Far: 43736\n",
      "Iteration took: 13.95 secs\n",
      "Current learning rate: 0.003990328388409525\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #10 --------------------\n",
      "Average Episodic Length: 174.07\n",
      "Average Episodic Return: -44.03\n",
      "Average Loss: -0.00175\n",
      "Timesteps So Far: 48610\n",
      "Iteration took: 16.83 secs\n",
      "Current learning rate: 0.0038915627853432096\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #11 --------------------\n",
      "Average Episodic Length: 219.23\n",
      "Average Episodic Return: -39.22\n",
      "Average Loss: -0.00181\n",
      "Timesteps So Far: 53433\n",
      "Iteration took: 19.73 secs\n",
      "Current learning rate: 0.003795241754101456\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #12 --------------------\n",
      "Average Episodic Length: 146.24\n",
      "Average Episodic Return: -13.62\n",
      "Average Loss: -0.00181\n",
      "Timesteps So Far: 58259\n",
      "Iteration took: 14.62 secs\n",
      "Current learning rate: 0.0037013047884835227\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #13 --------------------\n",
      "Average Episodic Length: 241.2\n",
      "Average Episodic Return: -8.48\n",
      "Average Loss: -0.00186\n",
      "Timesteps So Far: 63083\n",
      "Iteration took: 19.55 secs\n",
      "Current learning rate: 0.0036096928798925805\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #14 --------------------\n",
      "Average Episodic Length: 260.32\n",
      "Average Episodic Return: -15.26\n",
      "Average Loss: -0.00185\n",
      "Timesteps So Far: 68029\n",
      "Iteration took: 19.52 secs\n",
      "Current learning rate: 0.003520348480268149\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #15 --------------------\n",
      "Average Episodic Length: 544.89\n",
      "Average Episodic Return: 16.33\n",
      "Average Loss: -0.00182\n",
      "Timesteps So Far: 72933\n",
      "Iteration took: 24.91 secs\n",
      "Current learning rate: 0.0034332154659359997\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #16 --------------------\n",
      "Average Episodic Length: 376.07\n",
      "Average Episodic Return: 4.16\n",
      "Average Loss: -0.0018\n",
      "Timesteps So Far: 78198\n",
      "Iteration took: 22.77 secs\n",
      "Current learning rate: 0.003348239102352821\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #17 --------------------\n",
      "Average Episodic Length: 375.62\n",
      "Average Episodic Return: 6.45\n",
      "Average Loss: -0.00183\n",
      "Timesteps So Far: 83081\n",
      "Iteration took: 23.04 secs\n",
      "Current learning rate: 0.0032653660097234946\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #18 --------------------\n",
      "Average Episodic Length: 432.31\n",
      "Average Episodic Return: 26.25\n",
      "Average Loss: -0.00185\n",
      "Timesteps So Far: 88701\n",
      "Iteration took: 26.81 secs\n",
      "Current learning rate: 0.0031845441294693906\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #19 --------------------\n",
      "Average Episodic Length: 644.88\n",
      "Average Episodic Return: -26.62\n",
      "Average Loss: -0.00185\n",
      "Timesteps So Far: 93860\n",
      "Iteration took: 23.29 secs\n",
      "Current learning rate: 0.0031057226915266094\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #20 --------------------\n",
      "Average Episodic Length: 537.0\n",
      "Average Episodic Return: 1.87\n",
      "Average Loss: -0.00185\n",
      "Timesteps So Far: 99230\n",
      "Iteration took: 25.1 secs\n",
      "Current learning rate: 0.0030288521824536397\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #21 --------------------\n",
      "Average Episodic Length: 358.43\n",
      "Average Episodic Return: -1.76\n",
      "Average Loss: -0.00187\n",
      "Timesteps So Far: 104248\n",
      "Iteration took: 22.95 secs\n",
      "Current learning rate: 0.0029538843143283823\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #22 --------------------\n",
      "Average Episodic Length: 701.14\n",
      "Average Episodic Return: -20.5\n",
      "Average Loss: -0.00186\n",
      "Timesteps So Far: 109156\n",
      "Iteration took: 23.95 secs\n",
      "Current learning rate: 0.002880771994415019\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #23 --------------------\n",
      "Average Episodic Length: 721.75\n",
      "Average Episodic Return: -20.34\n",
      "Average Loss: -0.00189\n",
      "Timesteps So Far: 114930\n",
      "Iteration took: 27.91 secs\n",
      "Current learning rate: 0.0028094692955816644\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #24 --------------------\n",
      "Average Episodic Length: 629.88\n",
      "Average Episodic Return: -38.64\n",
      "Average Loss: -0.00189\n",
      "Timesteps So Far: 119969\n",
      "Iteration took: 23.37 secs\n",
      "Current learning rate: 0.0027399314274502108\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #25 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 79.79\n",
      "Average Loss: -0.00185\n",
      "Timesteps So Far: 124969\n",
      "Iteration took: 23.73 secs\n",
      "Current learning rate: 0.002672114708260257\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #26 --------------------\n",
      "Average Episodic Length: 732.29\n",
      "Average Episodic Return: -19.23\n",
      "Average Loss: -0.00183\n",
      "Timesteps So Far: 130095\n",
      "Iteration took: 18.8 secs\n",
      "Current learning rate: 0.002605976537429438\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #27 --------------------\n",
      "Average Episodic Length: 856.0\n",
      "Average Episodic Return: 47.18\n",
      "Average Loss: -0.00181\n",
      "Timesteps So Far: 135231\n",
      "Iteration took: 24.32 secs\n",
      "Current learning rate: 0.0025414753687929208\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #28 --------------------\n",
      "Average Episodic Length: 601.0\n",
      "Average Episodic Return: -8.59\n",
      "Average Loss: -0.0018\n",
      "Timesteps So Far: 140640\n",
      "Iteration took: 19.95 secs\n",
      "Current learning rate: 0.0024785706845052535\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #29 --------------------\n",
      "Average Episodic Length: 744.14\n",
      "Average Episodic Return: 26.77\n",
      "Average Loss: -0.00178\n",
      "Timesteps So Far: 145849\n",
      "Iteration took: 20.71 secs\n",
      "Current learning rate: 0.0024172229695881807\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #30 --------------------\n",
      "Average Episodic Length: 620.22\n",
      "Average Episodic Return: 55.77\n",
      "Average Loss: -0.00177\n",
      "Timesteps So Far: 151431\n",
      "Iteration took: 24.98 secs\n",
      "Current learning rate: 0.002357393687108429\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #31 --------------------\n",
      "Average Episodic Length: 750.14\n",
      "Average Episodic Return: -7.95\n",
      "Average Loss: -0.0018\n",
      "Timesteps So Far: 156682\n",
      "Iteration took: 26.01 secs\n",
      "Current learning rate: 0.002299045253969875\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #32 --------------------\n",
      "Average Episodic Length: 791.43\n",
      "Average Episodic Return: 26.13\n",
      "Average Loss: -0.00178\n",
      "Timesteps So Far: 162222\n",
      "Iteration took: 26.22 secs\n",
      "Current learning rate: 0.002242141017304885\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #33 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 46.23\n",
      "Average Loss: -0.00178\n",
      "Timesteps So Far: 167222\n",
      "Iteration took: 27.51 secs\n",
      "Current learning rate: 0.002186645231450001\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #34 --------------------\n",
      "Average Episodic Length: 787.57\n",
      "Average Episodic Return: 35.11\n",
      "Average Loss: -0.00177\n",
      "Timesteps So Far: 172735\n",
      "Iteration took: 27.27 secs\n",
      "Current learning rate: 0.0021325230354915076\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #35 --------------------\n",
      "Average Episodic Length: 682.38\n",
      "Average Episodic Return: 57.26\n",
      "Average Loss: -0.00175\n",
      "Timesteps So Far: 178194\n",
      "Iteration took: 24.64 secs\n",
      "Current learning rate: 0.0020797404313667688\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #36 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 58.37\n",
      "Average Loss: -0.00172\n",
      "Timesteps So Far: 183194\n",
      "Iteration took: 27.8 secs\n",
      "Current learning rate: 0.0020282642625075913\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #37 --------------------\n",
      "Average Episodic Length: 745.14\n",
      "Average Episodic Return: -18.38\n",
      "Average Loss: -0.00173\n",
      "Timesteps So Far: 188410\n",
      "Iteration took: 21.77 secs\n",
      "Current learning rate: 0.001978062193012188\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #38 --------------------\n",
      "Average Episodic Length: 803.0\n",
      "Average Episodic Return: 3.93\n",
      "Average Loss: -0.00173\n",
      "Timesteps So Far: 193228\n",
      "Iteration took: 20.64 secs\n",
      "Current learning rate: 0.0019291026873326578\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #39 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 64.2\n",
      "Average Loss: -0.00171\n",
      "Timesteps So Far: 198228\n",
      "Iteration took: 23.74 secs\n",
      "Current learning rate: 0.0018813549904652326\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #40 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 50.31\n",
      "Average Loss: -0.00171\n",
      "Timesteps So Far: 203228\n",
      "Iteration took: 20.1 secs\n",
      "Current learning rate: 0.001834789108630835\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #41 --------------------\n",
      "Average Episodic Length: 878.67\n",
      "Average Episodic Return: -15.89\n",
      "Average Loss: -0.00171\n",
      "Timesteps So Far: 208500\n",
      "Iteration took: 21.85 secs\n",
      "Current learning rate: 0.0017893757904338186\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #42 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 59.98\n",
      "Average Loss: -0.00171\n",
      "Timesteps So Far: 213500\n",
      "Iteration took: 26.75 secs\n",
      "Current learning rate: 0.001745086508487051\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #43 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 52.06\n",
      "Average Loss: -0.00169\n",
      "Timesteps So Far: 218500\n",
      "Iteration took: 26.48 secs\n",
      "Current learning rate: 0.0017018934414918026\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #44 --------------------\n",
      "Average Episodic Length: 893.67\n",
      "Average Episodic Return: 28.76\n",
      "Average Loss: -0.00168\n",
      "Timesteps So Far: 223862\n",
      "Iteration took: 25.2 secs\n",
      "Current learning rate: 0.0016597694567611774\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #45 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 91.39\n",
      "Average Loss: -0.00167\n",
      "Timesteps So Far: 228862\n",
      "Iteration took: 26.01 secs\n",
      "Current learning rate: 0.00161868809317611\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #46 --------------------\n",
      "Average Episodic Length: 856.33\n",
      "Average Episodic Return: 82.7\n",
      "Average Loss: -0.00165\n",
      "Timesteps So Far: 234000\n",
      "Iteration took: 26.87 secs\n",
      "Current learning rate: 0.0015786235445632267\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #47 --------------------\n",
      "Average Episodic Length: 814.5\n",
      "Average Episodic Return: 20.74\n",
      "Average Loss: -0.00167\n",
      "Timesteps So Far: 238887\n",
      "Iteration took: 21.91 secs\n",
      "Current learning rate: 0.0015395506434841214\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #48 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 62.34\n",
      "Average Loss: -0.00164\n",
      "Timesteps So Far: 243887\n",
      "Iteration took: 26.15 secs\n",
      "Current learning rate: 0.0015014448454258697\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #49 --------------------\n",
      "Average Episodic Length: 709.0\n",
      "Average Episodic Return: 71.42\n",
      "Average Loss: -0.00162\n",
      "Timesteps So Far: 249559\n",
      "Iteration took: 25.72 secs\n",
      "Current learning rate: 0.0014642822133828456\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #50 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 74.45\n",
      "Average Loss: -0.00161\n",
      "Timesteps So Far: 254559\n",
      "Iteration took: 23.56 secs\n",
      "Current learning rate: 0.0014280394028201597\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #51 --------------------\n",
      "Average Episodic Length: 758.14\n",
      "Average Episodic Return: 61.36\n",
      "Average Loss: -0.00159\n",
      "Timesteps So Far: 259866\n",
      "Iteration took: 27.05 secs\n",
      "Current learning rate: 0.0013926936470092677\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #52 --------------------\n",
      "Average Episodic Length: 858.5\n",
      "Average Episodic Return: 72.59\n",
      "Average Loss: -0.00158\n",
      "Timesteps So Far: 265017\n",
      "Iteration took: 23.54 secs\n",
      "Current learning rate: 0.001358222742726545\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #53 --------------------\n",
      "Average Episodic Length: 862.33\n",
      "Average Episodic Return: 117.02\n",
      "Average Loss: -0.00156\n",
      "Timesteps So Far: 270191\n",
      "Iteration took: 23.32 secs\n",
      "Current learning rate: 0.0013246050363058361\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #54 --------------------\n",
      "Average Episodic Length: 860.33\n",
      "Average Episodic Return: 105.65\n",
      "Average Loss: -0.00154\n",
      "Timesteps So Far: 275353\n",
      "Iteration took: 20.22 secs\n",
      "Current learning rate: 0.0012918194100362227\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #55 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 99.83\n",
      "Average Loss: -0.00153\n",
      "Timesteps So Far: 280353\n",
      "Iteration took: 21.51 secs\n",
      "Current learning rate: 0.0012598452688964623\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #56 --------------------\n",
      "Average Episodic Length: 859.17\n",
      "Average Episodic Return: 114.63\n",
      "Average Loss: -0.00152\n",
      "Timesteps So Far: 285508\n",
      "Iteration took: 16.09 secs\n",
      "Current learning rate: 0.001228662527617768\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #57 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 109.81\n",
      "Average Loss: -0.0015\n",
      "Timesteps So Far: 290508\n",
      "Iteration took: 22.22 secs\n",
      "Current learning rate: 0.0011982515980667996\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #58 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 117.04\n",
      "Average Loss: -0.00149\n",
      "Timesteps So Far: 295508\n",
      "Iteration took: 26.19 secs\n",
      "Current learning rate: 0.0011685933769409404\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #59 --------------------\n",
      "Average Episodic Length: 874.17\n",
      "Average Episodic Return: 111.47\n",
      "Average Loss: -0.00148\n",
      "Timesteps So Far: 300753\n",
      "Iteration took: 24.33 secs\n",
      "Current learning rate: 0.0011396692337681334\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #60 --------------------\n",
      "Average Episodic Length: 783.0\n",
      "Average Episodic Return: 88.82\n",
      "Average Loss: -0.0015\n",
      "Timesteps So Far: 306234\n",
      "Iteration took: 25.09 secs\n",
      "Current learning rate: 0.0011114609992037348\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #61 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 99.29\n",
      "Average Loss: -0.00149\n",
      "Timesteps So Far: 311234\n",
      "Iteration took: 24.02 secs\n",
      "Current learning rate: 0.0010839509536170356\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #62 --------------------\n",
      "Average Episodic Length: 867.0\n",
      "Average Episodic Return: 105.9\n",
      "Average Loss: -0.00148\n",
      "Timesteps So Far: 316436\n",
      "Iteration took: 24.09 secs\n",
      "Current learning rate: 0.0010571218159602814\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #63 --------------------\n",
      "Average Episodic Length: 883.17\n",
      "Average Episodic Return: 113.5\n",
      "Average Loss: -0.00148\n",
      "Timesteps So Far: 321735\n",
      "Iteration took: 22.77 secs\n",
      "Current learning rate: 0.0010309567329131965\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #64 --------------------\n",
      "Average Episodic Length: 807.14\n",
      "Average Episodic Return: 59.28\n",
      "Average Loss: -0.00148\n",
      "Timesteps So Far: 327385\n",
      "Iteration took: 22.62 secs\n",
      "Current learning rate: 0.0010054392682961968\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #65 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 116.27\n",
      "Average Loss: -0.00147\n",
      "Timesteps So Far: 332385\n",
      "Iteration took: 16.19 secs\n",
      "Current learning rate: 0.0009805533927456363\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #66 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 129.24\n",
      "Average Loss: -0.00147\n",
      "Timesteps So Far: 337385\n",
      "Iteration took: 18.45 secs\n",
      "Current learning rate: 0.0009562834736446059\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #67 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 110.93\n",
      "Average Loss: -0.00147\n",
      "Timesteps So Far: 342385\n",
      "Iteration took: 23.68 secs\n",
      "Current learning rate: 0.0009326142653029573\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #68 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 118.25\n",
      "Average Loss: -0.00145\n",
      "Timesteps So Far: 347385\n",
      "Iteration took: 23.13 secs\n",
      "Current learning rate: 0.0009095308993803826\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #69 --------------------\n",
      "Average Episodic Length: 777.0\n",
      "Average Episodic Return: 86.86\n",
      "Average Loss: -0.00144\n",
      "Timesteps So Far: 352824\n",
      "Iteration took: 24.41 secs\n",
      "Current learning rate: 0.0008870188755465357\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #70 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 123.39\n",
      "Average Loss: -0.00144\n",
      "Timesteps So Far: 357824\n",
      "Iteration took: 22.04 secs\n",
      "Current learning rate: 0.0008650640523723266\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #71 --------------------\n",
      "Average Episodic Length: 788.43\n",
      "Average Episodic Return: 101.66\n",
      "Average Loss: -0.00143\n",
      "Timesteps So Far: 363343\n",
      "Iteration took: 23.05 secs\n",
      "Current learning rate: 0.0008436526384466678\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #72 --------------------\n",
      "Average Episodic Length: 889.17\n",
      "Average Episodic Return: 136.79\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 368678\n",
      "Iteration took: 22.27 secs\n",
      "Current learning rate: 0.0008227711837130928\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #73 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 135.33\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 373678\n",
      "Iteration took: 22.03 secs\n",
      "Current learning rate: 0.0008024065710208029\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #74 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 125.45\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 378678\n",
      "Iteration took: 21.47 secs\n",
      "Current learning rate: 0.0007825460078848372\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #75 --------------------\n",
      "Average Episodic Length: 882.17\n",
      "Average Episodic Return: 62.08\n",
      "Average Loss: -0.0014\n",
      "Timesteps So Far: 383971\n",
      "Iteration took: 21.95 secs\n",
      "Current learning rate: 0.0007631770184501885\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #76 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 146.96\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 388971\n",
      "Iteration took: 19.6 secs\n",
      "Current learning rate: 0.0007442874356548164\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #77 --------------------\n",
      "Average Episodic Length: 871.33\n",
      "Average Episodic Return: 111.72\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 394199\n",
      "Iteration took: 17.65 secs\n",
      "Current learning rate: 0.0007258653935866376\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #78 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 144.09\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 399199\n",
      "Iteration took: 16.17 secs\n",
      "Current learning rate: 0.0007078993200296872\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #79 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 123.13\n",
      "Average Loss: -0.0014\n",
      "Timesteps So Far: 404199\n",
      "Iteration took: 21.47 secs\n",
      "Current learning rate: 0.0006903779291947756\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #80 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 146.14\n",
      "Average Loss: -0.0014\n",
      "Timesteps So Far: 409199\n",
      "Iteration took: 16.41 secs\n",
      "Current learning rate: 0.0006732902146300671\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #81 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 145.52\n",
      "Average Loss: -0.00138\n",
      "Timesteps So Far: 414199\n",
      "Iteration took: 17.17 secs\n",
      "Current learning rate: 0.0006566254423071324\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #82 --------------------\n",
      "Average Episodic Length: 866.17\n",
      "Average Episodic Return: 107.98\n",
      "Average Loss: -0.00138\n",
      "Timesteps So Far: 419396\n",
      "Iteration took: 22.13 secs\n",
      "Current learning rate: 0.0006403731438781306\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #83 --------------------\n",
      "Average Episodic Length: 780.14\n",
      "Average Episodic Return: 121.16\n",
      "Average Loss: -0.00138\n",
      "Timesteps So Far: 424857\n",
      "Iteration took: 23.31 secs\n",
      "Current learning rate: 0.0006245231100998819\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #84 --------------------\n",
      "Average Episodic Length: 933.67\n",
      "Average Episodic Return: 157.88\n",
      "Average Loss: -0.00137\n",
      "Timesteps So Far: 430459\n",
      "Iteration took: 23.39 secs\n",
      "Current learning rate: 0.0006090653844207053\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #85 --------------------\n",
      "Average Episodic Length: 854.17\n",
      "Average Episodic Return: 72.77\n",
      "Average Loss: -0.00138\n",
      "Timesteps So Far: 435584\n",
      "Iteration took: 21.37 secs\n",
      "Current learning rate: 0.0005939902567259883\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #86 --------------------\n",
      "Average Episodic Length: 865.33\n",
      "Average Episodic Return: 136.05\n",
      "Average Loss: -0.00137\n",
      "Timesteps So Far: 440776\n",
      "Iteration took: 20.87 secs\n",
      "Current learning rate: 0.0005792882572385626\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #87 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 131.77\n",
      "Average Loss: -0.00137\n",
      "Timesteps So Far: 445776\n",
      "Iteration took: 20.18 secs\n",
      "Current learning rate: 0.000564950150570052\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #88 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 152.82\n",
      "Average Loss: -0.00136\n",
      "Timesteps So Far: 450776\n",
      "Iteration took: 18.78 secs\n",
      "Current learning rate: 0.0005509669299194588\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #89 --------------------\n",
      "Average Episodic Length: 905.83\n",
      "Average Episodic Return: 164.77\n",
      "Average Loss: -0.00135\n",
      "Timesteps So Far: 456211\n",
      "Iteration took: 21.82 secs\n",
      "Current learning rate: 0.0005373298114153397\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #90 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 117.55\n",
      "Average Loss: -0.00134\n",
      "Timesteps So Far: 461211\n",
      "Iteration took: 16.28 secs\n",
      "Current learning rate: 0.0005240302285980222\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #91 --------------------\n",
      "Average Episodic Length: 974.0\n",
      "Average Episodic Return: 152.36\n",
      "Average Loss: -0.00135\n",
      "Timesteps So Far: 466081\n",
      "Iteration took: 13.59 secs\n",
      "Current learning rate: 0.0005110598270383922\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #92 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 161.41\n",
      "Average Loss: -0.00134\n",
      "Timesteps So Far: 471081\n",
      "Iteration took: 15.66 secs\n",
      "Current learning rate: 0.0004984104590898731\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #93 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 154.05\n",
      "Average Loss: -0.00133\n",
      "Timesteps So Far: 476081\n",
      "Iteration took: 14.82 secs\n",
      "Current learning rate: 0.00048607417877030007\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #94 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 125.84\n",
      "Average Loss: -0.00132\n",
      "Timesteps So Far: 481081\n",
      "Iteration took: 16.1 secs\n",
      "Current learning rate: 0.00047404323677047454\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #95 --------------------\n",
      "Average Episodic Length: 754.57\n",
      "Average Episodic Return: 132.5\n",
      "Average Loss: -0.00132\n",
      "Timesteps So Far: 486363\n",
      "Iteration took: 15.53 secs\n",
      "Current learning rate: 0.000462310075586263\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #96 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 135.72\n",
      "Average Loss: -0.00131\n",
      "Timesteps So Far: 491363\n",
      "Iteration took: 15.68 secs\n",
      "Current learning rate: 0.00045086732477118274\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #97 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 143.09\n",
      "Average Loss: -0.00131\n",
      "Timesteps So Far: 496363\n",
      "Iteration took: 16.37 secs\n",
      "Current learning rate: 0.00043970779630649146\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #98 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 124.17\n",
      "Average Loss: -0.0013\n",
      "Timesteps So Far: 501363\n",
      "Iteration took: 13.92 secs\n",
      "Current learning rate: 0.00042882448008587314\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #99 --------------------\n",
      "Average Episodic Length: 941.17\n",
      "Average Episodic Return: 166.98\n",
      "Average Loss: -0.00131\n",
      "Timesteps So Far: 507010\n",
      "Iteration took: 17.35 secs\n",
      "Current learning rate: 0.0004182105395118841\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #100 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 136.67\n",
      "Average Loss: -0.0013\n",
      "Timesteps So Far: 512010\n",
      "Iteration took: 15.57 secs\n",
      "Current learning rate: 0.0004078593072013916\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #101 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 121.25\n",
      "Average Loss: -0.00129\n",
      "Timesteps So Far: 517010\n",
      "Iteration took: 19.37 secs\n",
      "Current learning rate: 0.0003977642807973089\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #102 --------------------\n",
      "Average Episodic Length: 757.86\n",
      "Average Episodic Return: 133.5\n",
      "Average Loss: -0.00129\n",
      "Timesteps So Far: 522315\n",
      "Iteration took: 19.49 secs\n",
      "Current learning rate: 0.0003879191188839949\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #103 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 144.4\n",
      "Average Loss: -0.00128\n",
      "Timesteps So Far: 527315\n",
      "Iteration took: 18.23 secs\n",
      "Current learning rate: 0.0003783176370037524\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #104 --------------------\n",
      "Average Episodic Length: 867.33\n",
      "Average Episodic Return: 112.64\n",
      "Average Loss: -0.00128\n",
      "Timesteps So Far: 532519\n",
      "Iteration took: 18.74 secs\n",
      "Current learning rate: 0.0003689538037719237\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #105 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 123.6\n",
      "Average Loss: -0.00128\n",
      "Timesteps So Far: 537519\n",
      "Iteration took: 20.51 secs\n",
      "Current learning rate: 0.00035982173708814147\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #106 --------------------\n",
      "Average Episodic Length: 861.67\n",
      "Average Episodic Return: 135.22\n",
      "Average Loss: -0.00127\n",
      "Timesteps So Far: 542689\n",
      "Iteration took: 20.43 secs\n",
      "Current learning rate: 0.000350915700441357\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #107 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 126.74\n",
      "Average Loss: -0.00127\n",
      "Timesteps So Far: 547689\n",
      "Iteration took: 20.19 secs\n",
      "Current learning rate: 0.0003422300993063229\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #108 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 160.73\n",
      "Average Loss: -0.00126\n",
      "Timesteps So Far: 552689\n",
      "Iteration took: 19.6 secs\n",
      "Current learning rate: 0.00033375947762926685\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #109 --------------------\n",
      "Average Episodic Length: 797.14\n",
      "Average Episodic Return: 107.37\n",
      "Average Loss: -0.00126\n",
      "Timesteps So Far: 558269\n",
      "Iteration took: 22.12 secs\n",
      "Current learning rate: 0.0003254985144005508\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #110 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 165.41\n",
      "Average Loss: -0.00125\n",
      "Timesteps So Far: 563269\n",
      "Iteration took: 19.08 secs\n",
      "Current learning rate: 0.00031744202031215986\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #111 --------------------\n",
      "Average Episodic Length: 862.83\n",
      "Average Episodic Return: 136.76\n",
      "Average Loss: -0.00125\n",
      "Timesteps So Far: 568446\n",
      "Iteration took: 20.98 secs\n",
      "Current learning rate: 0.0003095849344979228\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #112 --------------------\n",
      "Average Episodic Length: 861.0\n",
      "Average Episodic Return: 122.96\n",
      "Average Loss: -0.00125\n",
      "Timesteps So Far: 573612\n",
      "Iteration took: 20.88 secs\n",
      "Current learning rate: 0.00030192232135441653\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #113 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 161.34\n",
      "Average Loss: -0.00125\n",
      "Timesteps So Far: 578612\n",
      "Iteration took: 20.6 secs\n",
      "Current learning rate: 0.0002944493674405568\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #114 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 145.66\n",
      "Average Loss: -0.00124\n",
      "Timesteps So Far: 583612\n",
      "Iteration took: 19.85 secs\n",
      "Current learning rate: 0.00028716137845392783\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #115 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 140.79\n",
      "Average Loss: -0.00124\n",
      "Timesteps So Far: 588612\n",
      "Iteration took: 20.09 secs\n",
      "Current learning rate: 0.00028005377628195197\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #116 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 106.66\n",
      "Average Loss: -0.00123\n",
      "Timesteps So Far: 593612\n",
      "Iteration took: 19.94 secs\n",
      "Current learning rate: 0.0002731220961260462\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #117 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 137.93\n",
      "Average Loss: -0.00123\n",
      "Timesteps So Far: 598612\n",
      "Iteration took: 15.96 secs\n",
      "Current learning rate: 0.0002663619836969594\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #118 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 141.61\n",
      "Average Loss: -0.00122\n",
      "Timesteps So Far: 603612\n",
      "Iteration took: 16.28 secs\n",
      "Current learning rate: 0.00025976919247952887\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #119 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 130.78\n",
      "Average Loss: -0.00122\n",
      "Timesteps So Far: 608612\n",
      "Iteration took: 17.27 secs\n",
      "Current learning rate: 0.00025333958106513686\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #120 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 146.46\n",
      "Average Loss: -0.00121\n",
      "Timesteps So Far: 613612\n",
      "Iteration took: 15.43 secs\n",
      "Current learning rate: 0.0002470691105501929\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #121 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 130.88\n",
      "Average Loss: -0.00121\n",
      "Timesteps So Far: 618612\n",
      "Iteration took: 17.74 secs\n",
      "Current learning rate: 0.00024095384199900632\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #122 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 127.11\n",
      "Average Loss: -0.0012\n",
      "Timesteps So Far: 623612\n",
      "Iteration took: 22.45 secs\n",
      "Current learning rate: 0.00023498993396945617\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #123 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 126.55\n",
      "Average Loss: -0.00119\n",
      "Timesteps So Far: 628612\n",
      "Iteration took: 22.99 secs\n",
      "Current learning rate: 0.00022917364009990388\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #124 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 136.81\n",
      "Average Loss: -0.00119\n",
      "Timesteps So Far: 633612\n",
      "Iteration took: 21.56 secs\n",
      "Current learning rate: 0.00022350130675583257\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #125 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 129.64\n",
      "Average Loss: -0.00119\n",
      "Timesteps So Far: 638612\n",
      "Iteration took: 23.22 secs\n",
      "Current learning rate: 0.00021796937073473543\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #126 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 131.93\n",
      "Average Loss: -0.00118\n",
      "Timesteps So Far: 643612\n",
      "Iteration took: 22.17 secs\n",
      "Current learning rate: 0.0002125743570278104\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #127 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 137.31\n",
      "Average Loss: -0.00118\n",
      "Timesteps So Far: 648612\n",
      "Iteration took: 16.86 secs\n",
      "Current learning rate: 0.0002073128766370564\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #128 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: 123.17\n",
      "Average Loss: -0.00118\n",
      "Timesteps So Far: 653612\n",
      "Iteration took: 17.72 secs\n",
      "Current learning rate: 0.00020218162444639832\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m total_timesteps_to_train \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m1_000_000\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps_to_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\model\\ppo_parallel.py:76\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self, total_timesteps)\u001b[0m\n\u001b[0;32m     73\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_so_far\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m t_sim \u001b[38;5;241m<\u001b[39m total_timesteps:   \n\u001b[1;32m---> 76\u001b[0m     obs, acts, log_probs, rews, ep_lens, vals, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     t_sim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(ep_lens)\n\u001b[0;32m     79\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\model\\ppo_parallel.py:162\u001b[0m, in \u001b[0;36mPPO.rollout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m batch_obs\u001b[38;5;241m.\u001b[39mappend(obs)\n\u001b[0;32m    160\u001b[0m ep_dones\u001b[38;5;241m.\u001b[39mappend(done)\n\u001b[1;32m--> 162\u001b[0m action, log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(obs)\n\u001b[0;32m    164\u001b[0m obs, rew, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\model\\ppo_parallel.py:202\u001b[0m, in \u001b[0;36mPPO.get_action\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m            Samples an action from the actor/critic network.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m\t\t\t\tlog_prob: the log probability of the selected action in the distribution\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         mean, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy(obs)\n\u001b[1;32m--> 202\u001b[0m         dist \u001b[38;5;241m=\u001b[39m \u001b[43mMultivariateNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m         action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m    205\u001b[0m         log_prob \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mlog_prob(action)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py:177\u001b[0m, in \u001b[0;36mMultivariateNormal.__init__\u001b[1;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m=\u001b[39m loc\u001b[38;5;241m.\u001b[39mexpand(batch_shape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    176\u001b[0m event_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale_tril \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril \u001b[38;5;241m=\u001b[39m scale_tril\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\distributions\\distribution.py:66\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip checking lazily-constructed args\u001b[39;00m\n\u001b[0;32m     65\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m---> 66\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\distributions\\constraints.py:220\u001b[0m, in \u001b[0;36m_IndependentConstraint.check\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreinterpreted_batch_ndims:\n\u001b[0;32m    222\u001b[0m         expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_constraint\u001b[38;5;241m.\u001b[39mevent_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreinterpreted_batch_ndims\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_timesteps_to_train =  1_000_000\n",
    "ppo.train(total_timesteps_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the Model\n",
    "\n",
    "Run multiple episodes from pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Query deterministic action from policy and run it\u001b[39;00m\n\u001b[0;32m     16\u001b[0m action \u001b[38;5;241m=\u001b[39m ppo\u001b[38;5;241m.\u001b[39mactor(obs)\n\u001b[1;32m---> 17\u001b[0m obs, rew, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;241m|\u001b[39m truncated\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Sum all episodic rewards as we go along\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:599\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    596\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(state, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:710\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen\u001b[38;5;241m.\u001b[39mblit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    709\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    711\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
