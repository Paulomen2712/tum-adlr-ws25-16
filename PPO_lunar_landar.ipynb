{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO\n",
    "---\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.ppo_3 import PPO\n",
    "from env.wrappers import LunarContinuous, LunarLanderWithUnknownWind,LunarLanderWithKnownWind\n",
    "from utils.logger import WandbSummaryWritter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the hyperparameters in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {\n",
    "#     'timesteps_per_batch': 1024 ,                # Number of timesteps to run per batch\n",
    "#     'max_timesteps_per_episode': 1200,           # Max number of timesteps per episode\n",
    "#     'n_updates_per_iteration': 5,                # Number of times to update actor/critic per iteration\n",
    "#     'lr': 2.5e-4 ,                                # Learning rate of actor optimizer\n",
    "#     'gamma': 0.95,                               # Discount factor to be applied when calculating Rewards-To-Go\n",
    "# }\n",
    "# hyperparameters = {'gamma': 0.999, 'lr_gamma': 0.995,\n",
    "#                    'max_timesteps_per_episode': 1200,'lr': 0.005 }\n",
    "\n",
    "hyperparameters = {}\n",
    "\n",
    "misc_hyperparameters = {\n",
    "    'env': LunarLanderWithKnownWind\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise wandb session in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = False\n",
    "if LOG:\n",
    "    logger = WandbSummaryWritter(project='lunar', config =misc_hyperparameters['env']().load_hyperparameters())\n",
    "else:\n",
    "    logger=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model fo the desired timestamps. Alternatively can specify a checkpoint to continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './ppo_checkpoints/non_wandb/ppo_policy_100.pth'\n",
    "LOAD_MODEL = True\n",
    "\n",
    "ppo = PPO(logger, **hyperparameters, **misc_hyperparameters)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    ppo.restore_savestate(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Model\n",
    "\n",
    "Train model for specified amount of timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Return: -414.31\n",
      "Average Actor Loss: -0.21016\n",
      "Average Critic Loss: 2235.5777529202974\n",
      "Average KL Divergence: 0.011430769027748075\n",
      "Iteration took: 10.48 secs, of which rollout took 8.65 secs and gradient updates took 1.82 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Return: -181.32\n",
      "Average Actor Loss: -0.21215\n",
      "Average Critic Loss: 1671.1588409423828\n",
      "Average KL Divergence: 0.011846140283579679\n",
      "Iteration took: 10.35 secs, of which rollout took 8.68 secs and gradient updates took 1.66 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #3 --------------------\n",
      "Average Episodic Return: -250.94\n",
      "Average Actor Loss: -0.21346\n",
      "Average Critic Loss: 1377.830073547363\n",
      "Average KL Divergence: 0.010745820818295053\n",
      "Iteration took: 10.79 secs, of which rollout took 8.9 secs and gradient updates took 1.89 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #4 --------------------\n",
      "Average Episodic Return: -140.07\n",
      "Average Actor Loss: -0.21493\n",
      "Average Critic Loss: 1154.1966930095966\n",
      "Average KL Divergence: 0.009914013054696205\n",
      "Iteration took: 11.2 secs, of which rollout took 9.41 secs and gradient updates took 1.78 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #5 --------------------\n",
      "Average Episodic Return: -147.9\n",
      "Average Actor Loss: -0.21528\n",
      "Average Critic Loss: 983.4801026799129\n",
      "Average KL Divergence: 0.009688500997553301\n",
      "Iteration took: 10.87 secs, of which rollout took 9.18 secs and gradient updates took 1.69 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #6 --------------------\n",
      "Average Episodic Return: -180.63\n",
      "Average Actor Loss: -0.21535\n",
      "Average Critic Loss: 879.7128800318791\n",
      "Average KL Divergence: 0.009678585910254556\n",
      "Iteration took: 10.91 secs, of which rollout took 9.23 secs and gradient updates took 1.67 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #7 --------------------\n",
      "Average Episodic Return: -171.39\n",
      "Average Actor Loss: -0.21549\n",
      "Average Critic Loss: 795.4765807099393\n",
      "Average KL Divergence: 0.009331923852624931\n",
      "Iteration took: 11.45 secs, of which rollout took 9.47 secs and gradient updates took 1.97 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #8 --------------------\n",
      "Average Episodic Return: -117.35\n",
      "Average Actor Loss: -0.21548\n",
      "Average Critic Loss: 725.9316355778622\n",
      "Average KL Divergence: 0.00912173832462031\n",
      "Iteration took: 11.64 secs, of which rollout took 9.67 secs and gradient updates took 1.96 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #9 --------------------\n",
      "Average Episodic Return: -145.56\n",
      "Average Actor Loss: -0.2156\n",
      "Average Critic Loss: 678.1435900500696\n",
      "Average KL Divergence: 0.008975526692700082\n",
      "Iteration took: 11.15 secs, of which rollout took 9.38 secs and gradient updates took 1.77 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #10 --------------------\n",
      "Average Episodic Return: -58.99\n",
      "Average Actor Loss: -0.21553\n",
      "Average Critic Loss: 638.5903904107901\n",
      "Average KL Divergence: 0.009033034430962848\n",
      "Iteration took: 11.55 secs, of which rollout took 9.76 secs and gradient updates took 1.78 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #11 --------------------\n",
      "Average Episodic Return: -120.23\n",
      "Average Actor Loss: -0.21537\n",
      "Average Critic Loss: 602.2097314154352\n",
      "Average KL Divergence: 0.009018818595636635\n",
      "Iteration took: 11.36 secs, of which rollout took 9.72 secs and gradient updates took 1.64 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #12 --------------------\n",
      "Average Episodic Return: -73.84\n",
      "Average Actor Loss: -0.21514\n",
      "Average Critic Loss: 572.1267630650447\n",
      "Average KL Divergence: 0.00898924255344378\n",
      "Iteration took: 11.28 secs, of which rollout took 9.58 secs and gradient updates took 1.69 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #13 --------------------\n",
      "Average Episodic Return: -109.45\n",
      "Average Actor Loss: -0.21531\n",
      "Average Critic Loss: 544.9090131432347\n",
      "Average KL Divergence: 0.009202845081895868\n",
      "Iteration took: 12.06 secs, of which rollout took 10.37 secs and gradient updates took 1.69 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #14 --------------------\n",
      "Average Episodic Return: -16.16\n",
      "Average Actor Loss: -0.21547\n",
      "Average Critic Loss: 517.913032246684\n",
      "Average KL Divergence: 0.009264835835335192\n",
      "Iteration took: 11.36 secs, of which rollout took 9.61 secs and gradient updates took 1.74 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #15 --------------------\n",
      "Average Episodic Return: -116.62\n",
      "Average Actor Loss: -0.21529\n",
      "Average Critic Loss: 501.1236985524496\n",
      "Average KL Divergence: 0.009266783598469396\n",
      "Iteration took: 12.99 secs, of which rollout took 11.27 secs and gradient updates took 1.71 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #16 --------------------\n",
      "Average Episodic Return: -82.04\n",
      "Average Actor Loss: -0.21509\n",
      "Average Critic Loss: 482.3238043473317\n",
      "Average KL Divergence: 0.009397683374898127\n",
      "Iteration took: 18.22 secs, of which rollout took 16.54 secs and gradient updates took 1.67 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #17 --------------------\n",
      "Average Episodic Return: -130.32\n",
      "Average Actor Loss: -0.21478\n",
      "Average Critic Loss: 472.9802313670853\n",
      "Average KL Divergence: 0.00944162917202781\n",
      "Iteration took: 17.25 secs, of which rollout took 15.45 secs and gradient updates took 1.8 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #18 --------------------\n",
      "Average Episodic Return: -90.92\n",
      "Average Actor Loss: -0.21463\n",
      "Average Critic Loss: 456.84461486849005\n",
      "Average KL Divergence: 0.009585258849877681\n",
      "Iteration took: 15.57 secs, of which rollout took 13.81 secs and gradient updates took 1.76 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #19 --------------------\n",
      "Average Episodic Return: -92.02\n",
      "Average Actor Loss: -0.2146\n",
      "Average Critic Loss: 441.3589574821564\n",
      "Average KL Divergence: 0.009717470703611165\n",
      "Iteration took: 17.61 secs, of which rollout took 15.84 secs and gradient updates took 1.75 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #20 --------------------\n",
      "Average Episodic Return: -147.63\n",
      "Average Actor Loss: -0.21452\n",
      "Average Critic Loss: 430.953898294889\n",
      "Average KL Divergence: 0.009830609546101385\n",
      "Iteration took: 17.89 secs, of which rollout took 16.26 secs and gradient updates took 1.62 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #21 --------------------\n",
      "Average Episodic Return: -104.95\n",
      "Average Actor Loss: -0.21426\n",
      "Average Critic Loss: 417.6450687303647\n",
      "Average KL Divergence: 0.009923064615041412\n",
      "Iteration took: 18.07 secs, of which rollout took 16.71 secs and gradient updates took 1.35 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #22 --------------------\n",
      "Average Episodic Return: -86.09\n",
      "Average Actor Loss: -0.21422\n",
      "Average Critic Loss: 402.7073775411485\n",
      "Average KL Divergence: 0.009888923437608721\n",
      "Iteration took: 17.47 secs, of which rollout took 15.65 secs and gradient updates took 1.81 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #23 --------------------\n",
      "Average Episodic Return: -127.2\n",
      "Average Actor Loss: -0.2142\n",
      "Average Critic Loss: 389.41794743681425\n",
      "Average KL Divergence: 0.009844356777330015\n",
      "Iteration took: 17.58 secs, of which rollout took 16.05 secs and gradient updates took 1.52 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #24 --------------------\n",
      "Average Episodic Return: -142.91\n",
      "Average Actor Loss: -0.2144\n",
      "Average Critic Loss: 375.9010246454141\n",
      "Average KL Divergence: 0.009961132166922819\n",
      "Iteration took: 23.07 secs, of which rollout took 21.25 secs and gradient updates took 1.81 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #25 --------------------\n",
      "Average Episodic Return: -125.8\n",
      "Average Actor Loss: -0.21428\n",
      "Average Critic Loss: 363.4850879452045\n",
      "Average KL Divergence: 0.009917334074697666\n",
      "Iteration took: 18.56 secs, of which rollout took 16.82 secs and gradient updates took 1.73 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #26 --------------------\n",
      "Average Episodic Return: -23.12\n",
      "Average Actor Loss: -0.21442\n",
      "Average Critic Loss: 351.5719414093085\n",
      "Average KL Divergence: 0.009837621736026241\n",
      "Iteration took: 21.43 secs, of which rollout took 19.99 secs and gradient updates took 1.43 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #27 --------------------\n",
      "Average Episodic Return: -9.79\n",
      "Average Actor Loss: -0.2143\n",
      "Average Critic Loss: 340.40974124354176\n",
      "Average KL Divergence: 0.009743812130734735\n",
      "Iteration took: 19.78 secs, of which rollout took 17.93 secs and gradient updates took 1.85 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #28 --------------------\n",
      "Average Episodic Return: -30.0\n",
      "Average Actor Loss: -0.21428\n",
      "Average Critic Loss: 331.1599577191111\n",
      "Average KL Divergence: 0.009754048319094393\n",
      "Iteration took: 20.84 secs, of which rollout took 19.19 secs and gradient updates took 1.65 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #29 --------------------\n",
      "Average Episodic Return: -37.92\n",
      "Average Actor Loss: -0.21425\n",
      "Average Critic Loss: 321.9889622179835\n",
      "Average KL Divergence: 0.009724039651652862\n",
      "Iteration took: 22.43 secs, of which rollout took 20.69 secs and gradient updates took 1.73 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #30 --------------------\n",
      "Average Episodic Return: -75.27\n",
      "Average Actor Loss: -0.21418\n",
      "Average Critic Loss: 313.6712924497554\n",
      "Average KL Divergence: 0.009740866825498011\n",
      "Iteration took: 20.93 secs, of which rollout took 19.04 secs and gradient updates took 1.88 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #31 --------------------\n",
      "Average Episodic Return: -99.27\n",
      "Average Actor Loss: -0.21414\n",
      "Average Critic Loss: 305.77843518765917\n",
      "Average KL Divergence: 0.009748293332474567\n",
      "Iteration took: 21.57 secs, of which rollout took 19.82 secs and gradient updates took 1.74 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #32 --------------------\n",
      "Average Episodic Return: -11.36\n",
      "Average Actor Loss: -0.21402\n",
      "Average Critic Loss: 297.79376048044514\n",
      "Average KL Divergence: 0.009742729125785728\n",
      "Iteration took: 25.11 secs, of which rollout took 23.28 secs and gradient updates took 1.82 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #33 --------------------\n",
      "Average Episodic Return: -115.76\n",
      "Average Actor Loss: -0.21396\n",
      "Average Critic Loss: 290.0734067882413\n",
      "Average KL Divergence: 0.009673476724406212\n",
      "Iteration took: 18.25 secs, of which rollout took 16.8 secs and gradient updates took 1.45 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #34 --------------------\n",
      "Average Episodic Return: 5.04\n",
      "Average Actor Loss: -0.21398\n",
      "Average Critic Loss: 282.64753682020023\n",
      "Average KL Divergence: 0.009657675036054345\n",
      "Iteration took: 17.54 secs, of which rollout took 16.17 secs and gradient updates took 1.36 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #35 --------------------\n",
      "Average Episodic Return: -2.63\n",
      "Average Actor Loss: -0.21396\n",
      "Average Critic Loss: 275.74843814409695\n",
      "Average KL Divergence: 0.009662200948372383\n",
      "Iteration took: 18.55 secs, of which rollout took 16.82 secs and gradient updates took 1.73 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #36 --------------------\n",
      "Average Episodic Return: -18.25\n",
      "Average Actor Loss: -0.21397\n",
      "Average Critic Loss: 268.9642440434195\n",
      "Average KL Divergence: 0.009660137616041587\n",
      "Iteration took: 22.1 secs, of which rollout took 20.56 secs and gradient updates took 1.54 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #37 --------------------\n",
      "Average Episodic Return: -43.41\n",
      "Average Actor Loss: -0.21396\n",
      "Average Critic Loss: 262.58668635808505\n",
      "Average KL Divergence: 0.009618847257035339\n",
      "Iteration took: 23.54 secs, of which rollout took 21.35 secs and gradient updates took 2.19 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #38 --------------------\n",
      "Average Episodic Return: -119.44\n",
      "Average Actor Loss: -0.21386\n",
      "Average Critic Loss: 256.33810903224867\n",
      "Average KL Divergence: 0.009601857574314168\n",
      "Iteration took: 22.31 secs, of which rollout took 20.26 secs and gradient updates took 2.04 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #39 --------------------\n",
      "Average Episodic Return: -142.98\n",
      "Average Actor Loss: -0.21387\n",
      "Average Critic Loss: 251.47513282642328\n",
      "Average KL Divergence: 0.009645739512517534\n",
      "Iteration took: 23.19 secs, of which rollout took 21.43 secs and gradient updates took 1.75 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #40 --------------------\n",
      "Average Episodic Return: -66.48\n",
      "Average Actor Loss: -0.21381\n",
      "Average Critic Loss: 245.8195046981481\n",
      "Average KL Divergence: 0.009593621694604135\n",
      "Iteration took: 23.76 secs, of which rollout took 21.98 secs and gradient updates took 1.77 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #41 --------------------\n",
      "Average Episodic Return: -6.39\n",
      "Average Actor Loss: -0.21373\n",
      "Average Critic Loss: 240.50193488808105\n",
      "Average KL Divergence: 0.009608429778864218\n",
      "Iteration took: 25.96 secs, of which rollout took 24.22 secs and gradient updates took 1.74 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #42 --------------------\n",
      "Average Episodic Return: -29.09\n",
      "Average Actor Loss: -0.21371\n",
      "Average Critic Loss: 235.84733505257753\n",
      "Average KL Divergence: 0.00965734496412301\n",
      "Iteration took: 21.33 secs, of which rollout took 19.56 secs and gradient updates took 1.76 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #43 --------------------\n",
      "Average Episodic Return: -24.94\n",
      "Average Actor Loss: -0.21374\n",
      "Average Critic Loss: 230.92826713948426\n",
      "Average KL Divergence: 0.00974409381063917\n",
      "Iteration took: 27.55 secs, of which rollout took 25.57 secs and gradient updates took 1.97 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #44 --------------------\n",
      "Average Episodic Return: 45.2\n",
      "Average Actor Loss: -0.21375\n",
      "Average Critic Loss: 225.9520911223405\n",
      "Average KL Divergence: 0.009727994665892881\n",
      "Iteration took: 24.07 secs, of which rollout took 22.34 secs and gradient updates took 1.72 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #45 --------------------\n",
      "Average Episodic Return: 25.47\n",
      "Average Actor Loss: -0.21372\n",
      "Average Critic Loss: 221.45057485042474\n",
      "Average KL Divergence: 0.009743204191180172\n",
      "Iteration took: 18.01 secs, of which rollout took 16.18 secs and gradient updates took 1.82 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #46 --------------------\n",
      "Average Episodic Return: 83.9\n",
      "Average Actor Loss: -0.21366\n",
      "Average Critic Loss: 217.10956821888186\n",
      "Average KL Divergence: 0.009748931926301989\n",
      "Iteration took: 19.58 secs, of which rollout took 17.8 secs and gradient updates took 1.78 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #47 --------------------\n",
      "Average Episodic Return: 89.28\n",
      "Average Actor Loss: -0.21358\n",
      "Average Critic Loss: 212.68867285423306\n",
      "Average KL Divergence: 0.009671644467229455\n",
      "Iteration took: 19.09 secs, of which rollout took 17.27 secs and gradient updates took 1.81 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #48 --------------------\n",
      "Average Episodic Return: -2.92\n",
      "Average Actor Loss: -0.2135\n",
      "Average Critic Loss: 209.0482626763674\n",
      "Average KL Divergence: 0.009674415212877777\n",
      "Iteration took: 19.96 secs, of which rollout took 18.2 secs and gradient updates took 1.76 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #49 --------------------\n",
      "Average Episodic Return: -31.52\n",
      "Average Actor Loss: -0.21341\n",
      "Average Critic Loss: 205.5668427307527\n",
      "Average KL Divergence: 0.00964955666738992\n",
      "Iteration took: 20.41 secs, of which rollout took 18.44 secs and gradient updates took 1.96 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #50 --------------------\n",
      "Average Episodic Return: 51.76\n",
      "Average Actor Loss: -0.21337\n",
      "Average Critic Loss: 202.16306759995678\n",
      "Average KL Divergence: 0.009659630592113055\n",
      "Iteration took: 17.97 secs, of which rollout took 16.3 secs and gradient updates took 1.66 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "Checkpoint saved at ./ppo_checkpoints/non_wandb/ppo_policy_50.pth\n",
      "\n",
      "-------------------- Iteration #51 --------------------\n",
      "Average Episodic Return: -107.06\n",
      "Average Actor Loss: -0.21329\n",
      "Average Critic Loss: 199.09755957799075\n",
      "Average KL Divergence: 0.009725321521500858\n",
      "Iteration took: 18.28 secs, of which rollout took 16.61 secs and gradient updates took 1.65 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #52 --------------------\n",
      "Average Episodic Return: 60.76\n",
      "Average Actor Loss: -0.21322\n",
      "Average Critic Loss: 195.85238913597442\n",
      "Average KL Divergence: 0.009677859306171042\n",
      "Iteration took: 19.43 secs, of which rollout took 17.73 secs and gradient updates took 1.7 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #53 --------------------\n",
      "Average Episodic Return: 111.98\n",
      "Average Actor Loss: -0.21322\n",
      "Average Critic Loss: 192.6448127469408\n",
      "Average KL Divergence: 0.009732204749904381\n",
      "Iteration took: 19.09 secs, of which rollout took 17.61 secs and gradient updates took 1.48 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #54 --------------------\n",
      "Average Episodic Return: 42.99\n",
      "Average Actor Loss: -0.21318\n",
      "Average Critic Loss: 189.40585141918942\n",
      "Average KL Divergence: 0.009722735025399061\n",
      "Iteration took: 21.02 secs, of which rollout took 18.88 secs and gradient updates took 2.14 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #55 --------------------\n",
      "Average Episodic Return: 69.65\n",
      "Average Actor Loss: -0.21317\n",
      "Average Critic Loss: 186.7791423592201\n",
      "Average KL Divergence: 0.00973941410805761\n",
      "Iteration took: 20.38 secs, of which rollout took 18.79 secs and gradient updates took 1.58 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #56 --------------------\n",
      "Average Episodic Return: 96.92\n",
      "Average Actor Loss: -0.21317\n",
      "Average Critic Loss: 183.62160693449636\n",
      "Average KL Divergence: 0.009714736203368947\n",
      "Iteration took: 17.71 secs, of which rollout took 16.08 secs and gradient updates took 1.63 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #57 --------------------\n",
      "Average Episodic Return: 50.03\n",
      "Average Actor Loss: -0.2131\n",
      "Average Critic Loss: 181.0812329408289\n",
      "Average KL Divergence: 0.00970948914047838\n",
      "Iteration took: 22.52 secs, of which rollout took 20.03 secs and gradient updates took 2.48 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #58 --------------------\n",
      "Average Episodic Return: 15.13\n",
      "Average Actor Loss: -0.21297\n",
      "Average Critic Loss: 178.57993820998965\n",
      "Average KL Divergence: 0.009716294322189222\n",
      "Iteration took: 25.27 secs, of which rollout took 23.32 secs and gradient updates took 1.94 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #59 --------------------\n",
      "Average Episodic Return: 63.74\n",
      "Average Actor Loss: -0.21293\n",
      "Average Critic Loss: 176.1944065027162\n",
      "Average KL Divergence: 0.00973599958443549\n",
      "Iteration took: 19.26 secs, of which rollout took 17.54 secs and gradient updates took 1.71 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #60 --------------------\n",
      "Average Episodic Return: 65.07\n",
      "Average Actor Loss: -0.21289\n",
      "Average Critic Loss: 173.5515477225108\n",
      "Average KL Divergence: 0.009708207181409608\n",
      "Iteration took: 18.51 secs, of which rollout took 16.79 secs and gradient updates took 1.71 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #61 --------------------\n",
      "Average Episodic Return: 65.62\n",
      "Average Actor Loss: -0.21289\n",
      "Average Critic Loss: 171.05868452670143\n",
      "Average KL Divergence: 0.00968009963434571\n",
      "Iteration took: 23.23 secs, of which rollout took 21.28 secs and gradient updates took 1.94 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #62 --------------------\n",
      "Average Episodic Return: 117.4\n",
      "Average Actor Loss: -0.21298\n",
      "Average Critic Loss: 168.948715235903\n",
      "Average KL Divergence: 0.009708083390652121\n",
      "Iteration took: 18.72 secs, of which rollout took 16.9 secs and gradient updates took 1.81 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #63 --------------------\n",
      "Average Episodic Return: 101.28\n",
      "Average Actor Loss: -0.21293\n",
      "Average Critic Loss: 166.85881007605562\n",
      "Average KL Divergence: 0.00968833770294879\n",
      "Iteration took: 20.78 secs, of which rollout took 18.72 secs and gradient updates took 2.05 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #64 --------------------\n",
      "Average Episodic Return: 87.96\n",
      "Average Actor Loss: -0.21291\n",
      "Average Critic Loss: 164.34211750506924\n",
      "Average KL Divergence: 0.009643336958593585\n",
      "Iteration took: 20.1 secs, of which rollout took 18.26 secs and gradient updates took 1.84 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #65 --------------------\n",
      "Average Episodic Return: 128.2\n",
      "Average Actor Loss: -0.21291\n",
      "Average Critic Loss: 162.1498269811255\n",
      "Average KL Divergence: 0.009675854454937355\n",
      "Iteration took: 20.19 secs, of which rollout took 18.38 secs and gradient updates took 1.8 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #66 --------------------\n",
      "Average Episodic Return: 76.42\n",
      "Average Actor Loss: -0.21277\n",
      "Average Critic Loss: 160.2728992857091\n",
      "Average KL Divergence: 0.0097090599216487\n",
      "Iteration took: 19.72 secs, of which rollout took 17.9 secs and gradient updates took 1.82 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #67 --------------------\n",
      "Average Episodic Return: 52.61\n",
      "Average Actor Loss: -0.2128\n",
      "Average Critic Loss: 158.37422095500915\n",
      "Average KL Divergence: 0.009751874624554057\n",
      "Iteration took: 17.59 secs, of which rollout took 15.63 secs and gradient updates took 1.96 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #68 --------------------\n",
      "Average Episodic Return: 59.36\n",
      "Average Actor Loss: -0.2128\n",
      "Average Critic Loss: 156.231531183961\n",
      "Average KL Divergence: 0.00976323735072064\n",
      "Iteration took: 19.7 secs, of which rollout took 18.0 secs and gradient updates took 1.69 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #69 --------------------\n",
      "Average Episodic Return: 109.45\n",
      "Average Actor Loss: -0.21277\n",
      "Average Critic Loss: 154.71577848295038\n",
      "Average KL Divergence: 0.00978215444127134\n",
      "Iteration took: 18.24 secs, of which rollout took 16.05 secs and gradient updates took 2.18 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #70 --------------------\n",
      "Average Episodic Return: 72.51\n",
      "Average Actor Loss: -0.21271\n",
      "Average Critic Loss: 153.69508171578684\n",
      "Average KL Divergence: 0.010247440664522624\n",
      "Iteration took: 19.12 secs, of which rollout took 17.26 secs and gradient updates took 1.86 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #71 --------------------\n",
      "Average Episodic Return: 84.81\n",
      "Average Actor Loss: -0.21272\n",
      "Average Critic Loss: 152.08477741443065\n",
      "Average KL Divergence: 0.010230289985673281\n",
      "Iteration took: 18.56 secs, of which rollout took 16.7 secs and gradient updates took 1.85 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #72 --------------------\n",
      "Average Episodic Return: 47.64\n",
      "Average Actor Loss: -0.2126\n",
      "Average Critic Loss: 150.9436859718309\n",
      "Average KL Divergence: 0.01023888143178803\n",
      "Iteration took: 17.61 secs, of which rollout took 15.8 secs and gradient updates took 1.8 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #73 --------------------\n",
      "Average Episodic Return: 49.73\n",
      "Average Actor Loss: -0.21262\n",
      "Average Critic Loss: 149.8708543939824\n",
      "Average KL Divergence: 0.010239843966363947\n",
      "Iteration took: 19.83 secs, of which rollout took 17.91 secs and gradient updates took 1.92 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #74 --------------------\n",
      "Average Episodic Return: 45.13\n",
      "Average Actor Loss: -0.2126\n",
      "Average Critic Loss: 148.74649114777912\n",
      "Average KL Divergence: 0.010253895884583988\n",
      "Iteration took: 16.39 secs, of which rollout took 14.54 secs and gradient updates took 1.85 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #75 --------------------\n",
      "Average Episodic Return: 86.93\n",
      "Average Actor Loss: -0.21259\n",
      "Average Critic Loss: 147.2958745773572\n",
      "Average KL Divergence: 0.010235980501303477\n",
      "Iteration took: 17.98 secs, of which rollout took 15.58 secs and gradient updates took 2.39 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #76 --------------------\n",
      "Average Episodic Return: 86.35\n",
      "Average Actor Loss: -0.21258\n",
      "Average Critic Loss: 145.79074595831787\n",
      "Average KL Divergence: 0.010227095227757025\n",
      "Iteration took: 16.27 secs, of which rollout took 14.67 secs and gradient updates took 1.59 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #77 --------------------\n",
      "Average Episodic Return: 80.27\n",
      "Average Actor Loss: -0.21258\n",
      "Average Critic Loss: 144.33828115971178\n",
      "Average KL Divergence: 0.010234572314577601\n",
      "Iteration took: 14.15 secs, of which rollout took 12.51 secs and gradient updates took 1.64 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #78 --------------------\n",
      "Average Episodic Return: 57.11\n",
      "Average Actor Loss: -0.21253\n",
      "Average Critic Loss: 143.12693189561838\n",
      "Average KL Divergence: 0.010223687168050468\n",
      "Iteration took: 15.32 secs, of which rollout took 13.56 secs and gradient updates took 1.76 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #79 --------------------\n",
      "Average Episodic Return: 70.22\n",
      "Average Actor Loss: -0.21259\n",
      "Average Critic Loss: 142.51584048445872\n",
      "Average KL Divergence: 0.010227298866917818\n",
      "Iteration took: 14.21 secs, of which rollout took 12.43 secs and gradient updates took 1.78 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #80 --------------------\n",
      "Average Episodic Return: 109.02\n",
      "Average Actor Loss: -0.21259\n",
      "Average Critic Loss: 141.0608017607778\n",
      "Average KL Divergence: 0.010181503423366562\n",
      "Iteration took: 17.08 secs, of which rollout took 15.4 secs and gradient updates took 1.68 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #81 --------------------\n",
      "Average Episodic Return: 133.08\n",
      "Average Actor Loss: -0.21254\n",
      "Average Critic Loss: 140.45133947904404\n",
      "Average KL Divergence: 0.01021433366531623\n",
      "Iteration took: 14.62 secs, of which rollout took 12.96 secs and gradient updates took 1.65 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #82 --------------------\n",
      "Average Episodic Return: 92.81\n",
      "Average Actor Loss: -0.21253\n",
      "Average Critic Loss: 139.05975002798533\n",
      "Average KL Divergence: 0.010197148076529905\n",
      "Iteration took: 15.08 secs, of which rollout took 13.42 secs and gradient updates took 1.66 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #83 --------------------\n",
      "Average Episodic Return: 124.42\n",
      "Average Actor Loss: -0.21247\n",
      "Average Critic Loss: 138.1044921806612\n",
      "Average KL Divergence: 0.010235652881876153\n",
      "Iteration took: 15.24 secs, of which rollout took 13.59 secs and gradient updates took 1.65 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #84 --------------------\n",
      "Average Episodic Return: 153.13\n",
      "Average Actor Loss: -0.2125\n",
      "Average Critic Loss: 136.5293147209854\n",
      "Average KL Divergence: 0.010175557115816117\n",
      "Iteration took: 14.95 secs, of which rollout took 13.29 secs and gradient updates took 1.65 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #85 --------------------\n",
      "Average Episodic Return: 86.04\n",
      "Average Actor Loss: -0.21248\n",
      "Average Critic Loss: 135.56152690903093\n",
      "Average KL Divergence: 0.010194252519894812\n",
      "Iteration took: 15.89 secs, of which rollout took 14.2 secs and gradient updates took 1.69 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #86 --------------------\n",
      "Average Episodic Return: 119.27\n",
      "Average Actor Loss: -0.21249\n",
      "Average Critic Loss: 134.5340853867089\n",
      "Average KL Divergence: 0.010177967211603276\n",
      "Iteration took: 14.98 secs, of which rollout took 13.34 secs and gradient updates took 1.64 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #87 --------------------\n",
      "Average Episodic Return: 112.09\n",
      "Average Actor Loss: -0.21245\n",
      "Average Critic Loss: 133.5942587535904\n",
      "Average KL Divergence: 0.010203584239035364\n",
      "Iteration took: 14.77 secs, of which rollout took 12.99 secs and gradient updates took 1.78 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #88 --------------------\n",
      "Average Episodic Return: 27.56\n",
      "Average Actor Loss: -0.21222\n",
      "Average Critic Loss: 133.5640786020541\n",
      "Average KL Divergence: 0.010265375013294734\n",
      "Iteration took: 16.28 secs, of which rollout took 14.62 secs and gradient updates took 1.65 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #89 --------------------\n",
      "Average Episodic Return: 55.76\n",
      "Average Actor Loss: -0.21218\n",
      "Average Critic Loss: 132.77521686634836\n",
      "Average KL Divergence: 0.010282582912761684\n",
      "Iteration took: 13.76 secs, of which rollout took 12.06 secs and gradient updates took 1.69 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #90 --------------------\n",
      "Average Episodic Return: 48.07\n",
      "Average Actor Loss: -0.21214\n",
      "Average Critic Loss: 132.1179190208005\n",
      "Average KL Divergence: 0.010321989863278777\n",
      "Iteration took: 14.21 secs, of which rollout took 12.27 secs and gradient updates took 1.93 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #91 --------------------\n",
      "Average Episodic Return: 63.42\n",
      "Average Actor Loss: -0.21216\n",
      "Average Critic Loss: 131.12899480664618\n",
      "Average KL Divergence: 0.010364038566960483\n",
      "Iteration took: 15.51 secs, of which rollout took 13.67 secs and gradient updates took 1.83 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #92 --------------------\n",
      "Average Episodic Return: 53.93\n",
      "Average Actor Loss: -0.21212\n",
      "Average Critic Loss: 130.46102799008221\n",
      "Average KL Divergence: 0.01041018916341506\n",
      "Iteration took: 14.0 secs, of which rollout took 12.19 secs and gradient updates took 1.8 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #93 --------------------\n",
      "Average Episodic Return: 93.58\n",
      "Average Actor Loss: -0.21212\n",
      "Average Critic Loss: 130.00727749709458\n",
      "Average KL Divergence: 0.01044098149385476\n",
      "Iteration took: 15.54 secs, of which rollout took 13.72 secs and gradient updates took 1.82 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #94 --------------------\n",
      "Average Episodic Return: 97.2\n",
      "Average Actor Loss: -0.21211\n",
      "Average Critic Loss: 129.26882037199948\n",
      "Average KL Divergence: 0.010452971476790978\n",
      "Iteration took: 14.7 secs, of which rollout took 12.85 secs and gradient updates took 1.84 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #95 --------------------\n",
      "Average Episodic Return: 44.5\n",
      "Average Actor Loss: -0.21212\n",
      "Average Critic Loss: 128.28345108992175\n",
      "Average KL Divergence: 0.010440113153639283\n",
      "Iteration took: 15.3 secs, of which rollout took 13.55 secs and gradient updates took 1.74 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #96 --------------------\n",
      "Average Episodic Return: 35.56\n",
      "Average Actor Loss: -0.21209\n",
      "Average Critic Loss: 127.50239332853698\n",
      "Average KL Divergence: 0.010428147178375919\n",
      "Iteration took: 14.41 secs, of which rollout took 12.54 secs and gradient updates took 1.86 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #97 --------------------\n",
      "Average Episodic Return: 28.53\n",
      "Average Actor Loss: -0.2121\n",
      "Average Critic Loss: 127.02488183760151\n",
      "Average KL Divergence: 0.01043090921686654\n",
      "Iteration took: 14.52 secs, of which rollout took 12.7 secs and gradient updates took 1.81 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #98 --------------------\n",
      "Average Episodic Return: 58.94\n",
      "Average Actor Loss: -0.21212\n",
      "Average Critic Loss: 126.1274428040912\n",
      "Average KL Divergence: 0.010416969313813623\n",
      "Iteration took: 14.82 secs, of which rollout took 12.98 secs and gradient updates took 1.83 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #99 --------------------\n",
      "Average Episodic Return: 93.47\n",
      "Average Actor Loss: -0.21212\n",
      "Average Critic Loss: 125.25800190539255\n",
      "Average KL Divergence: 0.010415901642406746\n",
      "Iteration took: 15.93 secs, of which rollout took 14.13 secs and gradient updates took 1.79 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #100 --------------------\n",
      "Average Episodic Return: 76.88\n",
      "Average Actor Loss: -0.21211\n",
      "Average Critic Loss: 124.26016111934645\n",
      "Average KL Divergence: 0.010421598826490686\n",
      "Iteration took: 17.84 secs, of which rollout took 16.04 secs and gradient updates took 1.79 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "Checkpoint saved at ./ppo_checkpoints/non_wandb/ppo_policy_100.pth\n",
      "\n",
      "-------------------- Iteration #101 --------------------\n",
      "Average Episodic Return: 128.14\n",
      "Average Actor Loss: -0.21213\n",
      "Average Critic Loss: 123.30023051405443\n",
      "Average KL Divergence: 0.010412855018682188\n",
      "Iteration took: 14.41 secs, of which rollout took 12.71 secs and gradient updates took 1.68 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #102 --------------------\n",
      "Average Episodic Return: 173.02\n",
      "Average Actor Loss: -0.21214\n",
      "Average Critic Loss: 122.45177355944033\n",
      "Average KL Divergence: 0.01038799654027064\n",
      "Iteration took: 15.37 secs, of which rollout took 13.62 secs and gradient updates took 1.74 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #103 --------------------\n",
      "Average Episodic Return: 74.84\n",
      "Average Actor Loss: -0.21213\n",
      "Average Critic Loss: 122.10361628990462\n",
      "Average KL Divergence: 0.010353772267063664\n",
      "Iteration took: 15.0 secs, of which rollout took 13.27 secs and gradient updates took 1.72 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #104 --------------------\n",
      "Average Episodic Return: 62.38\n",
      "Average Actor Loss: -0.21214\n",
      "Average Critic Loss: 121.87044194635645\n",
      "Average KL Divergence: 0.01034752824966704\n",
      "Iteration took: 14.24 secs, of which rollout took 12.48 secs and gradient updates took 1.75 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #105 --------------------\n",
      "Average Episodic Return: 78.34\n",
      "Average Actor Loss: -0.21214\n",
      "Average Critic Loss: 121.47191381397265\n",
      "Average KL Divergence: 0.010328891971263549\n",
      "Iteration took: 14.65 secs, of which rollout took 12.93 secs and gradient updates took 1.71 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #106 --------------------\n",
      "Average Episodic Return: 70.94\n",
      "Average Actor Loss: -0.21211\n",
      "Average Critic Loss: 121.3627280179795\n",
      "Average KL Divergence: 0.010347708767384264\n",
      "Iteration took: 13.47 secs, of which rollout took 11.74 secs and gradient updates took 1.72 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #107 --------------------\n",
      "Average Episodic Return: 91.68\n",
      "Average Actor Loss: -0.21211\n",
      "Average Critic Loss: 120.84496390346912\n",
      "Average KL Divergence: 0.010319279106054475\n",
      "Iteration took: 13.83 secs, of which rollout took 12.06 secs and gradient updates took 1.76 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #108 --------------------\n",
      "Average Episodic Return: 93.65\n",
      "Average Actor Loss: -0.2121\n",
      "Average Critic Loss: 120.17830902813932\n",
      "Average KL Divergence: 0.010328095535892713\n",
      "Iteration took: 15.24 secs, of which rollout took 13.52 secs and gradient updates took 1.71 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #109 --------------------\n",
      "Average Episodic Return: 82.74\n",
      "Average Actor Loss: -0.21209\n",
      "Average Critic Loss: 119.52974993756479\n",
      "Average KL Divergence: 0.010333346578900613\n",
      "Iteration took: 13.97 secs, of which rollout took 12.21 secs and gradient updates took 1.75 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #110 --------------------\n",
      "Average Episodic Return: 100.02\n",
      "Average Actor Loss: -0.2121\n",
      "Average Critic Loss: 119.00630133955212\n",
      "Average KL Divergence: 0.010337501284990721\n",
      "Iteration took: 14.76 secs, of which rollout took 12.93 secs and gradient updates took 1.82 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\model\\ppo_3.py:87\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcritic_lr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_lr\n\u001b[0;32m     86\u001b[0m rollout_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()  \n\u001b[1;32m---> 87\u001b[0m obs, acts, log_probs, advantages, returns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m rollout_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_so_far\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m it \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\model\\ppo_3.py:218\u001b[0m, in \u001b[0;36mPPO.rollout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m     actions, logprobs, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mact(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(next_obs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    216\u001b[0m     next_obs, rewards, next_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdones\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mcompute_advantages(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mget_value(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(next_obs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)), next_done)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mget_rollot_data()\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\utils\\storage.py:29\u001b[0m, in \u001b[0;36mStorage.store_batch\u001b[1;34m(self, obs, actions, logprobs, rewards, values, dones)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRollout buffer overflow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep]\u001b[38;5;241m.\u001b[39mcopy_(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep]\u001b[38;5;241m.\u001b[39mcopy_(actions)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep]\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(rewards)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppo.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the Model\n",
    "\n",
    "Run multiple episodes from pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# val_rews, val_dur = ppo.validate(10, False, True, False)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ppo.test()\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m wind_vals, base_z, adpt_z \u001b[38;5;241m=\u001b[39m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_encoders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(wind_vals)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_z)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\model\\ppo_3.py:354\u001b[0m, in \u001b[0;36mPPO.validate_encoders\u001b[1;34m(self, num_iters)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# Convert to tensor and send through encoders\u001b[39;00m\n\u001b[0;32m    353\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(random_obs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 354\u001b[0m base_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    355\u001b[0m adpt_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_policy\u001b[38;5;241m.\u001b[39mencode(obs_tensor)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    357\u001b[0m base_z\u001b[38;5;241m.\u001b[39mappend(base_output)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\networks\\mlp.py:45\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pmsar\\.conda\\envs\\adlr\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "# ppo.validate(val_iter=30)\n",
    "ppo.device = 'cpu'\n",
    "import numpy as np\n",
    "# val_rews, val_dur = ppo.validate(10, False, True, False)\n",
    "# ppo.test()\n",
    "\n",
    "wind_vals, base_z, adpt_z = ppo.validate_encoders()\n",
    "\n",
    "print(wind_vals)\n",
    "print(base_z)\n",
    "print(adpt_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
