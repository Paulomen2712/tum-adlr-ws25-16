{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO\n",
    "---\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import wandb\n",
    "\n",
    "from model.ppo_2 import PPO\n",
    "from env.wrappers import LunarContinuous, LunarLanderWithUnknownWind,LunarLanderWithKnownWind\n",
    "from utils.logger import WandbSummaryWritter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the hyperparameters in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_hyperparameters = {\n",
    "    'save_freq': 0 ,  \n",
    "    'val_freq': 10,\n",
    "    'val_iter': 10,\n",
    "    'env': LunarLanderWithKnownWind\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise wandb session in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOTAL_TIMESTEPS_TO_TRAIN = 500\n",
    "VAL_ITER = 20\n",
    "MAX_RUN_COUNT = 30\n",
    "sweep_config = {\n",
    "    'method': 'bayes', \n",
    "    'metric': {\n",
    "        'name': 'validation_rewards',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'actor_lr': {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 0.1\n",
    "        },\n",
    "        'critic_lr': {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 0.1\n",
    "        },\n",
    "        'adp_lr': {\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 0.1\n",
    "        },\n",
    "        'gamma': {\n",
    "            'min': 0.9,\n",
    "            'max': 1.\n",
    "        },\n",
    "        'lam': {\n",
    "            'min': 0.9,\n",
    "            'max': 1.\n",
    "        },\n",
    "        'max_grad_norm': {\n",
    "            \"min\": 0.1,\n",
    "            \"max\": 10, \n",
    "        },\n",
    "        'n_updates_per_iteration': {\n",
    "            'values': list(range(1, 21))\n",
    "        },\n",
    "        'num_envs': {\n",
    "            'values': list(range(1, 100))\n",
    "        },\n",
    "        'anneal_lr': {\n",
    "            'values': [True, False]\n",
    "        },\n",
    "        'num_steps': {\n",
    "            'distribution': 'q_uniform',\n",
    "            'min': 300,\n",
    "            'max': 4000,\n",
    "            'q': 100\n",
    "        },\n",
    "        'adp_num_steps': {\n",
    "            'distribution': 'q_uniform',\n",
    "            'min': 200,\n",
    "            'max': 1000,\n",
    "            'q': 10\n",
    "        },\n",
    "        'anneal_discount': {\n",
    "            'distribution': 'q_uniform',\n",
    "            'min': 1,\n",
    "            'max': 1000,\n",
    "            'q': 10\n",
    "        },\n",
    "        'batches': {\n",
    "            'distribution': 'q_uniform',\n",
    "            \"min\": 1,     # 2^0\n",
    "            \"max\": 1024,  # 2^10\n",
    "            \"q\": 2 \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config = None):\n",
    "    logger = WandbSummaryWritter(project='lunar', config =config)\n",
    "    ppo = ppo = PPO(logger,**misc_hyperparameters) if config is None else PPO(summary_writter=logger, **config, **misc_hyperparameters)\n",
    "    ppo.train()\n",
    "\n",
    "    val_rews, val_dur = ppo.validate(VAL_ITER, False)\n",
    "\n",
    "    wandb.log({\n",
    "        \"validation_rewards\": val_rews,\n",
    "        \"validation_duration\": val_dur\n",
    "        # \"max_reward_video\": wandb.Video(f\"videos\\\\rl-video-episode-{np.argmax(val_rews)}.mp4\", fps=4, format=\"mp4\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model fo the desired timestamps. Alternatively can specify a checkpoint to continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('constraints' was unexpected)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. max_grad_norm uses q_log_uniform, where min/max specify base-e exponents. Use q_log_uniform_values to specify limit values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: yk0hcuv3\n",
      "Sweep URL: https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dt6solfi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.07511353134200377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadp_lr: 0.006720398486064176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadp_num_steps: 680\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tanneal_lr: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches: 940\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.0758837188329859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9426677298554624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlam: 0.9383715033610108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_updates_per_iteration: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_envs: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_steps: 3900\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpmsaraiva2712\u001b[0m (\u001b[33mpmsaraiva2712-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\wandb\\run-20241214_190346-dt6solfi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/dt6solfi' target=\"_blank\">olive-sweep-1</a></strong> to <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/dt6solfi' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/dt6solfi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Return: -203.93\n",
      "Average Actor Loss: -0.21083\n",
      "Average Critic Loss: 1110.1379979647122\n",
      "Average KL Divergence: 0.010224226825476553\n",
      "Iteration took: 10.99 secs, of which rollout took 8.99 secs and gradient updates took 2.0 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Return: -286.45\n",
      "Average Actor Loss: -0.2147\n",
      "Average Critic Loss: 809.7173865098218\n",
      "Average KL Divergence: 0.00943904954939661\n",
      "Iteration took: 11.47 secs, of which rollout took 9.49 secs and gradient updates took 1.96 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average adp Loss: 2.46015\n",
      "Iteration took: 8.13 secs, of which rollout took 7.49 secs and gradient updates took 0.62 secs\n",
      "Current adp learning rate: 0.005\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_learning_rate</td><td>▁▁</td></tr><tr><td>adp_learning_rate</td><td>▁</td></tr><tr><td>average_actor_loss</td><td>█▁</td></tr><tr><td>average_adapt_loss</td><td>▁</td></tr><tr><td>average_critic_loss</td><td>█▁</td></tr><tr><td>average_episode_rewards</td><td>█▁</td></tr><tr><td>critic_learning_rate</td><td>▁▁</td></tr><tr><td>simulated_iterations</td><td>▁█▁</td></tr><tr><td>validation_duration</td><td>▁</td></tr><tr><td>validation_rewards</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_learning_rate</td><td>0.005</td></tr><tr><td>adp_learning_rate</td><td>0.005</td></tr><tr><td>average_actor_loss</td><td>-0.2147</td></tr><tr><td>average_adapt_loss</td><td>2.46015</td></tr><tr><td>average_critic_loss</td><td>809.71739</td></tr><tr><td>average_episode_rewards</td><td>-286.45041</td></tr><tr><td>critic_learning_rate</td><td>0.0075</td></tr><tr><td>iteration_compute</td><td>8.13</td></tr><tr><td>simulated_iterations</td><td>1</td></tr><tr><td>validation_duration</td><td>94.65</td></tr><tr><td>validation_rewards</td><td>-169.82104</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-1</strong> at: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/dt6solfi' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/dt6solfi</a><br/> View project at: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241214_190346-dt6solfi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ymtjzc3i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.06045633618669653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadp_lr: 0.011641022868937928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadp_num_steps: 990\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tanneal_lr: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches: 610\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.08427680579865444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9655166989159883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlam: 0.9051284899170832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_updates_per_iteration: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_envs: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_steps: 1300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\wandb\\run-20241214_190428-ymtjzc3i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/ymtjzc3i' target=\"_blank\">hardy-sweep-2</a></strong> to <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/ymtjzc3i' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/ymtjzc3i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Return: -229.58\n",
      "Average Actor Loss: -0.21186\n",
      "Average Critic Loss: 1286.7947630662184\n",
      "Average KL Divergence: 0.012249548944572988\n",
      "Iteration took: 12.34 secs, of which rollout took 10.5 secs and gradient updates took 1.84 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Return: -153.72\n",
      "Average Actor Loss: -0.21372\n",
      "Average Critic Loss: 946.1518800295316\n",
      "Average KL Divergence: 0.011448690700322353\n",
      "Iteration took: 13.09 secs, of which rollout took 11.14 secs and gradient updates took 1.93 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average adp Loss: 2.61578\n",
      "Iteration took: 8.93 secs, of which rollout took 8.24 secs and gradient updates took 0.66 secs\n",
      "Current adp learning rate: 0.005\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_learning_rate</td><td>▁▁</td></tr><tr><td>adp_learning_rate</td><td>▁</td></tr><tr><td>average_actor_loss</td><td>█▁</td></tr><tr><td>average_adapt_loss</td><td>▁</td></tr><tr><td>average_critic_loss</td><td>█▁</td></tr><tr><td>average_episode_rewards</td><td>▁█</td></tr><tr><td>critic_learning_rate</td><td>▁▁</td></tr><tr><td>simulated_iterations</td><td>▁█▁</td></tr><tr><td>validation_duration</td><td>▁</td></tr><tr><td>validation_rewards</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_learning_rate</td><td>0.005</td></tr><tr><td>adp_learning_rate</td><td>0.005</td></tr><tr><td>average_actor_loss</td><td>-0.21372</td></tr><tr><td>average_adapt_loss</td><td>2.61578</td></tr><tr><td>average_critic_loss</td><td>946.15188</td></tr><tr><td>average_episode_rewards</td><td>-153.71815</td></tr><tr><td>critic_learning_rate</td><td>0.0075</td></tr><tr><td>iteration_compute</td><td>8.93</td></tr><tr><td>simulated_iterations</td><td>1</td></tr><tr><td>validation_duration</td><td>119.45</td></tr><tr><td>validation_rewards</td><td>-190.75366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-2</strong> at: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/ymtjzc3i' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/ymtjzc3i</a><br/> View project at: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241214_190428-ymtjzc3i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 07sj19af with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactor_lr: 0.07727284594022034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadp_lr: 0.06563532485614942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadp_num_steps: 340\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tanneal_lr: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatches: 240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcritic_lr: 0.004400780044034726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9768005088270716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlam: 0.982104341104846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_updates_per_iteration: 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_envs: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_steps: 3300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\wandb\\run-20241214_190510-07sj19af</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/07sj19af' target=\"_blank\">stilted-sweep-3</a></strong> to <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/yk0hcuv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/07sj19af' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/07sj19af</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Return: -173.09\n",
      "Average Actor Loss: -0.2101\n",
      "Average Critic Loss: 1285.3066014216497\n",
      "Average KL Divergence: 0.009372806259824966\n",
      "Iteration took: 11.38 secs, of which rollout took 9.41 secs and gradient updates took 1.97 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Return: -159.82\n",
      "Average Actor Loss: -0.21188\n",
      "Average Critic Loss: 898.9989279820369\n",
      "Average KL Divergence: 0.009518731126319416\n",
      "Iteration took: 11.79 secs, of which rollout took 9.51 secs and gradient updates took 2.26 secs\n",
      "Current actor learning rate: 0.005\n",
      "Current critic learning rate: 0.0075\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average adp Loss: 2.67086\n",
      "Iteration took: 8.12 secs, of which rollout took 7.49 secs and gradient updates took 0.61 secs\n",
      "Current adp learning rate: 0.005\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"lunar\")\n",
    "wandb.agent(sweep_id, function=train_model, count=MAX_RUN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lr': 0.033773968633186116, 'lam': 0.965122224947915, 'gamma': 0.9391731546579618, 'lr_gamma': 0.99964198121568, 'max_grad_norm': 1.0549291822676827, 'n_sgd_batches': 8, 'timesteps_per_batch': 6600, 'n_updates_per_iteration': 17, 'max_timesteps_per_episode': 800}\n",
      "Best Metrics: {'val_rewards': -117.685825451997, '_runtime': 18.8714706, '_step': 2, '_timestamp': 1733497014.9633105, '_wandb': {'runtime': 18}, 'average_episode_lengths': 97.5, 'average_episode_rewards': -214.25900286086735, 'average_loss': 0.001098420703783631, 'learning_rate': 0.004990008995201681, 'max_reward_video': {'_type': 'video-file', 'path': 'media/videos/max_reward_video_2_de1368eb4a9cffe45bc9.mp4', 'sha256': 'de1368eb4a9cffe45bc98fb1781e53c0619e8cb010e012a453b94f289e4f54ad', 'size': 10645}, 'simulated_iterations': 2, 'simulated_timesteps': 9719, 'validation_duration': 76.4}\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "# Fetch the sweep object\n",
    "sweep = api.sweep(f\"pmsaraiva2712-tum/lunar/{sweep_id}\")\n",
    "\n",
    "# Fetch all runs from the sweep\n",
    "runs = sweep.runs\n",
    "\n",
    "# Sort runs by the metric you are optimizing for, e.g., 'val_loss'\n",
    "best_run = sorted(runs, key=lambda run: run.summary.get('val_rewards', float('-inf')), reverse=True)[0]\n",
    "\n",
    "# Extract best hyperparameters and metrics\n",
    "best_params = best_run.config\n",
    "best_metrics = best_run.summary\n",
    "\n",
    "# Print the best hyperparameters and metrics\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Metrics:\", best_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
