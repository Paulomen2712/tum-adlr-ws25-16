{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO\n",
    "---\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from model.ppo_parallel import PPO\n",
    "from model.network import ActorCritic\n",
    "from env.wrappers import LunarContinuous\n",
    "from gym.wrappers import RecordVideo\n",
    "from logger import WandbSummaryWritter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the hyperparameters in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_hyperparameters = {\n",
    "    'save_freq': 50  ,                           # How often we save in number of iterations\n",
    "    'num_workers': 8  ,\n",
    "    'seed': None \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise wandb session in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TIMESTEPS_TO_TRAIN = 500_000\n",
    "VAL_ITER = 30\n",
    "sweep_config = {\n",
    "    'method': 'bayes', \n",
    "    'metric': {\n",
    "        'name': 'val_rewards',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'lr': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.1\n",
    "        },\n",
    "        'gamma': {\n",
    "            'min': 0.9,\n",
    "            'max': 1.\n",
    "        },\n",
    "        'lr_gamma': {\n",
    "            'min': 0.999,\n",
    "            'max': 1.\n",
    "        },\n",
    "        'n_updates_per_iteration': {\n",
    "            'values': list(range(1, 21))\n",
    "        },\n",
    "        'max_timesteps_per_episode': {\n",
    "            'values': list(range(600, 2001, 200))\n",
    "        },\n",
    "        'timesteps_per_batch': {\n",
    "            'values': list(range(600, 5001, 200))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config = None):\n",
    "    logger = WandbSummaryWritter(project='lunar', config =config)\n",
    "    ppo = ppo = PPO(logger,**misc_hyperparameters) if config is None else PPO(summary_writter=logger, lr = config.lr, gamma = config.gamma, n_updates_per_iteration = config.n_updates_per_iteration, max_timesteps_per_episode = config.max_timesteps_per_episode, **misc_hyperparameters)\n",
    "    ppo.train(TOTAL_TIMESTEPS_TO_TRAIN)\n",
    "\n",
    "    env = LunarContinuous().make_environment_for_recording()\n",
    "    val_rews, val_dur = ppo.validate(VAL_ITER,env)\n",
    "\n",
    "    wandb.log({\n",
    "        \"val_rewards\": np.mean(val_rews),\n",
    "        \"validation_duration\": np.mean(val_dur),\n",
    "        \"max_reward_video\": wandb.Video(f\"videos\\\\rl-video-episode-{np.argmax(val_rews)}.mp4\", fps=4, format=\"mp4\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the model fo the desired timestamps. Alternatively can specify a checkpoint to continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: znsn2cbw\n",
      "Sweep URL: https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/znsn2cbw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yww6epaf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.9483407015108342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05268468266715958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_gamma: 0.9992078042272966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_timesteps_per_episode: 2000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_updates_per_iteration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimesteps_per_batch: 4200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpmsaraiva2712\u001b[0m (\u001b[33mpmsaraiva2712-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\pmsar\\git\\tum-adlr-ws25-16\\wandb\\run-20241202_161724-yww6epaf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/yww6epaf' target=\"_blank\">hardy-sweep-1</a></strong> to <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/znsn2cbw' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/znsn2cbw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/znsn2cbw' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/sweeps/znsn2cbw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pmsaraiva2712-tum/lunar/runs/yww6epaf' target=\"_blank\">https://wandb.ai/pmsaraiva2712-tum/lunar/runs/yww6epaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Iteration #1 --------------------\n",
      "Average Episodic Length: 98.31\n",
      "Average Episodic Return: -176.43\n",
      "Average Loss: 0.00131\n",
      "Timesteps So Far: 4817\n",
      "Iteration took: 7.11 secs\n",
      "Current learning rate: 0.0049950019996000405\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #2 --------------------\n",
      "Average Episodic Length: 104.61\n",
      "Average Episodic Return: -178.45\n",
      "Average Loss: -0.00119\n",
      "Timesteps So Far: 9629\n",
      "Iteration took: 6.9 secs\n",
      "Current learning rate: 0.004990008995201681\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #3 --------------------\n",
      "Average Episodic Length: 134.5\n",
      "Average Episodic Return: -141.81\n",
      "Average Loss: -0.00169\n",
      "Timesteps So Far: 14471\n",
      "Iteration took: 7.98 secs\n",
      "Current learning rate: 0.004985020981810917\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #4 --------------------\n",
      "Average Episodic Length: 108.62\n",
      "Average Episodic Return: -120.7\n",
      "Average Loss: -0.00196\n",
      "Timesteps So Far: 19359\n",
      "Iteration took: 7.12 secs\n",
      "Current learning rate: 0.004980037954438738\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #5 --------------------\n",
      "Average Episodic Length: 109.41\n",
      "Average Episodic Return: -109.81\n",
      "Average Loss: -0.00214\n",
      "Timesteps So Far: 24173\n",
      "Iteration took: 7.04 secs\n",
      "Current learning rate: 0.004975059908101118\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #6 --------------------\n",
      "Average Episodic Length: 123.21\n",
      "Average Episodic Return: -83.07\n",
      "Average Loss: -0.00225\n",
      "Timesteps So Far: 28978\n",
      "Iteration took: 7.09 secs\n",
      "Current learning rate: 0.004970086837819016\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #7 --------------------\n",
      "Average Episodic Length: 145.45\n",
      "Average Episodic Return: -77.91\n",
      "Average Loss: -0.00204\n",
      "Timesteps So Far: 33778\n",
      "Iteration took: 9.07 secs\n",
      "Current learning rate: 0.0049651187386183645\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #8 --------------------\n",
      "Average Episodic Length: 119.85\n",
      "Average Episodic Return: -101.25\n",
      "Average Loss: -0.00219\n",
      "Timesteps So Far: 38692\n",
      "Iteration took: 7.32 secs\n",
      "Current learning rate: 0.004960155605530073\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #9 --------------------\n",
      "Average Episodic Length: 137.14\n",
      "Average Episodic Return: -84.89\n",
      "Average Loss: -0.00196\n",
      "Timesteps So Far: 43492\n",
      "Iteration took: 7.16 secs\n",
      "Current learning rate: 0.004955197433590013\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #10 --------------------\n",
      "Average Episodic Length: 120.68\n",
      "Average Episodic Return: -63.39\n",
      "Average Loss: -0.00187\n",
      "Timesteps So Far: 48319\n",
      "Iteration took: 7.26 secs\n",
      "Current learning rate: 0.004950244217839021\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #11 --------------------\n",
      "Average Episodic Length: 120.08\n",
      "Average Episodic Return: -53.04\n",
      "Average Loss: -0.00162\n",
      "Timesteps So Far: 53122\n",
      "Iteration took: 7.17 secs\n",
      "Current learning rate: 0.004945295953322889\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #12 --------------------\n",
      "Average Episodic Length: 124.79\n",
      "Average Episodic Return: -39.29\n",
      "Average Loss: -0.00165\n",
      "Timesteps So Far: 57989\n",
      "Iteration took: 8.94 secs\n",
      "Current learning rate: 0.004940352635092364\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #13 --------------------\n",
      "Average Episodic Length: 146.76\n",
      "Average Episodic Return: -51.15\n",
      "Average Loss: -0.00166\n",
      "Timesteps So Far: 62832\n",
      "Iteration took: 8.72 secs\n",
      "Current learning rate: 0.004935414258203138\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #14 --------------------\n",
      "Average Episodic Length: 137.72\n",
      "Average Episodic Return: -37.18\n",
      "Average Loss: -0.00173\n",
      "Timesteps So Far: 67790\n",
      "Iteration took: 9.47 secs\n",
      "Current learning rate: 0.004930480817715845\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #15 --------------------\n",
      "Average Episodic Length: 150.28\n",
      "Average Episodic Return: -45.76\n",
      "Average Loss: -0.00162\n",
      "Timesteps So Far: 72599\n",
      "Iteration took: 8.95 secs\n",
      "Current learning rate: 0.004925552308696057\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #16 --------------------\n",
      "Average Episodic Length: 130.22\n",
      "Average Episodic Return: -40.62\n",
      "Average Loss: -0.00143\n",
      "Timesteps So Far: 77417\n",
      "Iteration took: 9.05 secs\n",
      "Current learning rate: 0.00492062872621428\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #17 --------------------\n",
      "Average Episodic Length: 154.94\n",
      "Average Episodic Return: -44.89\n",
      "Average Loss: -0.0012\n",
      "Timesteps So Far: 82375\n",
      "Iteration took: 9.64 secs\n",
      "Current learning rate: 0.004915710065345947\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #18 --------------------\n",
      "Average Episodic Length: 186.31\n",
      "Average Episodic Return: -58.67\n",
      "Average Loss: -0.0013\n",
      "Timesteps So Far: 87219\n",
      "Iteration took: 10.38 secs\n",
      "Current learning rate: 0.00491079632117141\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #19 --------------------\n",
      "Average Episodic Length: 232.24\n",
      "Average Episodic Return: -64.1\n",
      "Average Loss: -0.00131\n",
      "Timesteps So Far: 92096\n",
      "Iteration took: 13.09 secs\n",
      "Current learning rate: 0.004905887488775943\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #20 --------------------\n",
      "Average Episodic Length: 187.54\n",
      "Average Episodic Return: -42.28\n",
      "Average Loss: -0.00137\n",
      "Timesteps So Far: 96972\n",
      "Iteration took: 11.69 secs\n",
      "Current learning rate: 0.004900983563249731\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #21 --------------------\n",
      "Average Episodic Length: 201.92\n",
      "Average Episodic Return: -55.48\n",
      "Average Loss: -0.00142\n",
      "Timesteps So Far: 101818\n",
      "Iteration took: 9.77 secs\n",
      "Current learning rate: 0.0048960845396878675\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #22 --------------------\n",
      "Average Episodic Length: 149.7\n",
      "Average Episodic Return: -14.77\n",
      "Average Loss: -0.00149\n",
      "Timesteps So Far: 106758\n",
      "Iteration took: 8.35 secs\n",
      "Current learning rate: 0.004891190413190349\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #23 --------------------\n",
      "Average Episodic Length: 271.84\n",
      "Average Episodic Return: -36.01\n",
      "Average Loss: -0.00151\n",
      "Timesteps So Far: 111923\n",
      "Iteration took: 12.38 secs\n",
      "Current learning rate: 0.004886301178862068\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #24 --------------------\n",
      "Average Episodic Length: 305.89\n",
      "Average Episodic Return: -40.74\n",
      "Average Loss: -0.00154\n",
      "Timesteps So Far: 117429\n",
      "Iteration took: 13.34 secs\n",
      "Current learning rate: 0.0048814168318128135\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #25 --------------------\n",
      "Average Episodic Length: 355.31\n",
      "Average Episodic Return: -16.17\n",
      "Average Loss: -0.00156\n",
      "Timesteps So Far: 123114\n",
      "Iteration took: 15.96 secs\n",
      "Current learning rate: 0.00487653736715726\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #26 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: -45.35\n",
      "Average Loss: -0.00153\n",
      "Timesteps So Far: 128114\n",
      "Iteration took: 19.78 secs\n",
      "Current learning rate: 0.0048716627800149655\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #27 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: -47.79\n",
      "Average Loss: -0.00153\n",
      "Timesteps So Far: 133114\n",
      "Iteration took: 18.61 secs\n",
      "Current learning rate: 0.004866793065510369\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #28 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: -59.93\n",
      "Average Loss: -0.00152\n",
      "Timesteps So Far: 138114\n",
      "Iteration took: 16.45 secs\n",
      "Current learning rate: 0.004861928218772781\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #29 --------------------\n",
      "Average Episodic Length: 751.71\n",
      "Average Episodic Return: -79.73\n",
      "Average Loss: -0.00147\n",
      "Timesteps So Far: 143376\n",
      "Iteration took: 16.25 secs\n",
      "Current learning rate: 0.004857068234936381\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #30 --------------------\n",
      "Average Episodic Length: 859.5\n",
      "Average Episodic Return: -27.67\n",
      "Average Loss: -0.00144\n",
      "Timesteps So Far: 148533\n",
      "Iteration took: 19.42 secs\n",
      "Current learning rate: 0.004852213109140212\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #31 --------------------\n",
      "Average Episodic Length: 994.8\n",
      "Average Episodic Return: -43.76\n",
      "Average Loss: -0.0014\n",
      "Timesteps So Far: 153507\n",
      "Iteration took: 14.17 secs\n",
      "Current learning rate: 0.004847362836528178\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #32 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: -3.55\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 158507\n",
      "Iteration took: 17.71 secs\n",
      "Current learning rate: 0.004842517412249035\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #33 --------------------\n",
      "Average Episodic Length: 813.67\n",
      "Average Episodic Return: -76.61\n",
      "Average Loss: -0.00145\n",
      "Timesteps So Far: 163389\n",
      "Iteration took: 16.86 secs\n",
      "Current learning rate: 0.004837676831456388\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Iteration #34 --------------------\n",
      "Average Episodic Length: 1000.0\n",
      "Average Episodic Return: -31.37\n",
      "Average Loss: -0.00141\n",
      "Timesteps So Far: 168389\n",
      "Iteration took: 19.41 secs\n",
      "Current learning rate: 0.00483284108930869\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"lunar\")\n",
    "wandb.agent(sweep_id, function=train_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
